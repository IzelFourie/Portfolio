<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Izel Fourie Sørensen">
<meta name="dcterms.date" content="2024-10-01">

<title>Izel Fourie Sørensen - Statistical Learning: classification problem</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Izel Fourie Sørensen</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html">
 <span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html">
 <span class="menu-text">Resume</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/IzelFourie"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/izel-fourie-sørensen"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Statistical Learning: classification problem</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">code</div>
                <div class="quarto-category">analysis</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Izel Fourie Sørensen </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 1, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="cell">

</div>
<section id="goal" class="level2">
<h2 class="anchored" data-anchor-id="goal">Goal</h2>
<p>In this post I use different statistical models for predicting whether a person’s annual income will exceed $50K a year based on data in the “Census Income” data set.</p>
<div class="cell fig-cap-location-bottom" data-layout-align="left">

</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the necessary libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># car: VIF factor</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># caret: confusionMatrix</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># naniar: missing values</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># e1071: support vector classifier</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ROCR: ROC curves</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(<span class="st">"qgg"</span>, <span class="st">"corrplot"</span>, <span class="st">"ggplot2"</span>, <span class="st">"tidyr"</span>, <span class="st">"mlbench"</span>, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>               <span class="st">"readr"</span>, <span class="st">"data.table"</span>, <span class="st">"naniar"</span>, <span class="st">"car"</span>, <span class="st">"caret"</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">"xgboost"</span>, <span class="st">"dplyr"</span>, <span class="st">"Matrix"</span>, <span class="st">"e1071"</span>, <span class="st">"glmnet"</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>               <span class="st">"ROCR"</span>, <span class="st">"pROC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<!-- https://www.pexels.com/photo/hands-holding-us-dollar-bills-4968656/ -->
<p>The focus of this post is to determine which statistical model gives the best prediction of this binary outcome. I will compare logistic regression, XGBoost and the Support Vector Classifier models for their accuracy and precision in predicting the outcome. I will not spend a lot of time on explorative data analysis.</p>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>The data as well as information about the dataset can be found <a href="https://archive.ics.uci.edu/dataset/2/adult">here</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the Adult data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">"https://archive.ics.uci.edu/static/public/2/adult.zip"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>destfile <span class="ot">&lt;-</span> <span class="fu">tempfile</span>()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>exdir <span class="ot">&lt;-</span> <span class="fu">tempdir</span>()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(<span class="at">url=</span>url, <span class="at">destfile=</span>destfile)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">unzip</span>(destfile, <span class="at">exdir=</span>exdir)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># I am not showing the output of the following. It is not pretty to look at, but helps me identify the files downloaded in the zipped file.</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">list.files</span>(exdir, <span class="at">full.names =</span> <span class="cn">TRUE</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The Adult data comes in a train and test set, so no need to partition the data into a training and test set.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the train and test data sets</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df_train <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="fu">file.path</span>(exdir,<span class="st">"adult.data"</span>), <span class="at">data.table=</span><span class="cn">FALSE</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df_test <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="fu">file.path</span>(exdir,<span class="st">"adult.test"</span>), <span class="at">skip=</span><span class="dv">1</span>, <span class="at">data.table=</span><span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The variable names are given in the description of the data on the website. I added them manually.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(df_train) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"workclass"</span>, <span class="st">"fnlwgt"</span>, <span class="st">"education"</span>, <span class="st">"education_num"</span>,</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"marital_status"</span>, <span class="st">"occupation"</span>, <span class="st">"relationship"</span>, <span class="st">"race"</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"sex"</span>, <span class="st">"capital_gain"</span>, <span class="st">"capital_loss"</span>, <span class="st">"hours_per_week"</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"native_country"</span>, <span class="st">"income"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(df_test) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"workclass"</span>, <span class="st">"fnlwgt"</span>, <span class="st">"education"</span>, <span class="st">"education_num"</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"marital_status"</span>, <span class="st">"occupation"</span>, <span class="st">"relationship"</span>, <span class="st">"race"</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"sex"</span>, <span class="st">"capital_gain"</span>, <span class="st">"capital_loss"</span>, <span class="st">"hours_per_week"</span>,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"native_country"</span>, <span class="st">"income"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the structure of the data frames</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df_train)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df_test)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df_train)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean the test dataset income column by remove the "."</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Use fixed=TRUE to treat it as a literal string, and not a regular expression:</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>df_test<span class="sc">$</span>income <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"."</span>, <span class="st">""</span>, df_test<span class="sc">$</span>income, <span class="at">fixed=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The data consists of variables. The training data consists of 32561 observations and the test data of 16281.</p>
<p>Here is a quick view of what the data looks like.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  age        workclass fnlwgt education education_num     marital_status
1  39        State-gov  77516 Bachelors            13      Never-married
2  50 Self-emp-not-inc  83311 Bachelors            13 Married-civ-spouse
3  38          Private 215646   HS-grad             9           Divorced
4  53          Private 234721      11th             7 Married-civ-spouse
5  28          Private 338409 Bachelors            13 Married-civ-spouse
6  37          Private 284582   Masters            14 Married-civ-spouse
         occupation  relationship  race    sex capital_gain capital_loss
1      Adm-clerical Not-in-family White   Male         2174            0
2   Exec-managerial       Husband White   Male            0            0
3 Handlers-cleaners Not-in-family White   Male            0            0
4 Handlers-cleaners       Husband Black   Male            0            0
5    Prof-specialty          Wife Black Female            0            0
6   Exec-managerial          Wife White Female            0            0
  hours_per_week native_country income
1             40  United-States  &lt;=50K
2             13  United-States  &lt;=50K
3             40  United-States  &lt;=50K
4             40  United-States  &lt;=50K
5             40           Cuba  &lt;=50K
6             40  United-States  &lt;=50K</code></pre>
</div>
</div>
<p>Although I didn’t want to spend too much time on explorative data analysis, I couldn’t help looking at the income difference between men and women. (Just for fun I created the graph in Tableau.) The figure shows exactly what I expected: that the proportion of females earning more than $50K would be much lower than the proportion of males. The figure also shows that there is class imbalance in the dataset, since the class income &gt; $50K occurs less frequent than the other.</p>

<div class="tableauPlaceholder" id="viz1728455966947" style="position: relative"><noscript><a href="#"><img alt="Percentage of males and females that earned more or less than $50,000 in 1994. " src="https://public.tableau.com/static/images/Bo/Book1_17279468755020/Sheet2/1_rss.png" style="border: none"></a></noscript><object class="tableauViz" style="display:none;"><param name="host_url" value="https%3A%2F%2Fpublic.tableau.com%2F"> <param name="embed_code_version" value="3"> <param name="site_root" value=""><param name="name" value="Book1_17279468755020/Sheet2"><param name="tabs" value="no"><param name="toolbar" value="yes"><param name="static_image" value="https://public.tableau.com/static/images/Bo/Book1_17279468755020/Sheet2/1.png"> <param name="animate_transition" value="yes"><param name="display_static_image" value="yes"><param name="display_spinner" value="yes"><param name="display_overlay" value="yes"><param name="display_count" value="yes"><param name="language" value="en-GB"><param name="filter" value="publish=yes"></object></div>                
<script type="text/javascript">                    
var divElement = document.getElementById('viz1728455966947');
var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>

<p>The figure below shows the distribution of ages for people earning more or less than $50,000 per year. There is a clear shift towards older age for earning above $50K. The curve suggests that in 1994 middle-aged individuals were more likely to have incomes above $50K.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dev.off()</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># To see the age range where people are more likely to fall into a particular income bracket:</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_train, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">fill =</span> income)) <span class="sc">+</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Age distribution by income group"</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> <span class="st">"Age"</span>, <span class="at">Y =</span> <span class="st">"Density"</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"&lt;=50K"</span> <span class="ot">=</span> <span class="st">"#4E7AA7"</span>, <span class="st">"&gt;50K"</span> <span class="ot">=</span> <span class="st">"#E49343"</span>)) <span class="sc">+</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>()</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#,</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#panel.grid.minor = element_blank()</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Age Distribution by Income Group"</span>,</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age"</span>, <span class="at">y =</span> <span class="st">"Density"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="384"></p>
</div>
</div>
</section>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data preparation</h2>
<p>Join the training and test datasets so that I can edit the datasets as a whole.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the character variables to factors</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>df  <span class="ot">&lt;-</span> <span class="fu">rbind</span>(df_train,df_test)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>character_vars <span class="ot">&lt;-</span> <span class="fu">lapply</span>(df, class) <span class="sc">==</span> <span class="st">"character"</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Even though the website mentions missing data, there does not seem to be missing data in the train and test sets.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># colSums(is.na(df_train))</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># colSums(is.na(df_test))</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>There are duplicates in the data, but it is not unlikely that more than one person could have the same entries for the different variables in this dataset.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">any</span>(<span class="fu">duplicated</span>(df))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">duplicated</span>(df) <span class="sc">|</span> <span class="fu">duplicated</span>(df, <span class="at">fromLast =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Look at the distribution of the numerical columns by making box plots.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numeric colummns</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a boxplot of each numeric column</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>numeric_columns <span class="ot">&lt;-</span> df[, <span class="fu">sapply</span>(df, is.numeric)]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))  </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(<span class="fu">names</span>(numeric_columns), <span class="cf">function</span>(col) {</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">boxplot</span>(numeric_columns[[col]], <span class="at">main =</span> col, <span class="at">ylab =</span> col)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A closer look at the distribution of the capital_gain and capital_loss variables shows that their distribution is highly skewed to the right, with the majority of observations being zero. There are a few extreme outliers that are inflating the mean.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of capital_gain and capital_loss</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Summary of Capital Gain:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Summary of Capital Gain:</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df<span class="sc">$</span>capital_gain)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      0       0       0    1079       0   99999 </code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Summary of Capital Loss:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Summary of Capital Loss:</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df<span class="sc">$</span>capital_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    0.0     0.0     0.0    87.5     0.0  4356.0 </code></pre>
</div>
</div>
<p>I decide to change these variables to binary variables instead, where any value above zero is assigned “1” otherwise “0”.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_gain <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>capital_gain <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_gain <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>capital_gain)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_loss <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>capital_loss <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_loss <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>capital_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>I check for covariance between variables (correlated features) and variables with very low variance (below 1e-5).</p>
<p>The highest correlation is observed between <code>hours_per_week</code> and <code>education_num</code> with a value of 0.148.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at covariance between variables</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numerical features in the training data</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>num_vars <span class="ot">&lt;-</span> <span class="fu">sapply</span>(df_train, is.numeric)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute correlation matrix for numerical variables</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co"># None of the variables appear to be highly correlated</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(df_train[, num_vars], <span class="at">use =</span> <span class="st">"complete.obs"</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>cor_matrix</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize correlations with a heatmap</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(cor_matrix, <span class="at">method =</span> <span class="st">"color"</span>, <span class="at">tl.cex =</span> <span class="fl">0.7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Heatmap of correlations between numerical variables.</figcaption><p></p>
</figure>
</div>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at the variance of numerical variables</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate variance for each numeric column</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>variances <span class="ot">&lt;-</span> <span class="fu">apply</span>(df_train[, num_vars], <span class="dv">2</span>, var)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Find features with low variance (e.g., variance close to 0)</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>low_variance_features <span class="ot">&lt;-</span> <span class="fu">names</span>(variances[variances <span class="sc">&lt;</span> <span class="fl">1e-5</span>])</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Check for variables consisting of a single value</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>single_value_check <span class="ot">&lt;-</span> <span class="fu">sapply</span>(df_train, <span class="cf">function</span>(x) <span class="fu">length</span>(<span class="fu">unique</span>(x)) <span class="sc">==</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The number of observations for the different outcomes for predictor variable classes is important. It is preferable to have at least 10 observations for each level of the outcome variable for each of the predictor variable categories.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at the number of observations for different classes of categorical variables</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(df_train[,character_vars], table)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create contingency tables between each character variable and df$income</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>character_vars_pred <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">names</span>(df_train)[<span class="fu">sapply</span>(df_train, is.character)], <span class="st">"income"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>contingency_tables <span class="ot">&lt;-</span> <span class="fu">lapply</span>(character_vars_pred, <span class="cf">function</span>(var) {</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>(df_train[[var]], df_train<span class="sc">$</span>income)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Name each table by the character variable</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(contingency_tables) <span class="ot">&lt;-</span> character_vars_pred</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co"># View the contingency tables</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>contingency_tables</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>I decide to combine some of the categories for the variables workclass, education, occupation and native_country. These variables are edited as follows:</p>
<p><code>workclass</code><br>
Working Without_pay and Never_worked is very unlikely to result in an income above &gt;50K. I am merging these categories with the category “?”.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>workclass[df<span class="sc">$</span>workclass <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Without-pay"</span>, <span class="st">"Never-worked"</span>)] <span class="ot">&lt;-</span> <span class="st">"?"</span> </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>income, df<span class="sc">$</span>workclass)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>education</code><br>
Add Preschool, and the other grades up to 9th grade and call it pre-primary-school.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>education[df<span class="sc">$</span>education <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Preschool"</span>, <span class="st">"1st-4th"</span>, <span class="st">"5th-6th"</span>, <span class="st">"7th-8th"</span>, <span class="st">"9th"</span>)] <span class="ot">&lt;-</span> <span class="st">"pre-primary-school"</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>income, df<span class="sc">$</span>education)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>occupation</code><br>
Move Armed-Forces and Priv-house-serv to “?”</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>occupation[df<span class="sc">$</span>occupation <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Armed-Forces"</span>, <span class="st">"Priv-house-serv"</span>)] <span class="ot">&lt;-</span> <span class="st">"?"</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>income, df<span class="sc">$</span>occupation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>native_country</code><br>
Move all countries with that have less than 10 observations in the training data to a new category called “Other”.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a contingency table of income and native_country</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>contingency_table_native_country <span class="ot">&lt;-</span> <span class="fu">table</span>(df_train<span class="sc">$</span>income, df_train<span class="sc">$</span>native_country)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the native_country categories with fewer than 10 observations in any income row</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>low_count_country <span class="ot">&lt;-</span> <span class="fu">apply</span>(contingency_table_native_country, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">any</span>(x <span class="sc">&lt;</span> <span class="dv">10</span>))</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the countries that meet the condition</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>low_count_countries <span class="ot">&lt;-</span> <span class="fu">names</span>(low_count_country[low_count_country])</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Move all low count countries to a new category "other"</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>native_country[df<span class="sc">$</span>native_country <span class="sc">%in%</span> low_count_countries] <span class="ot">&lt;-</span> <span class="st">"Other"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Other minor adjustments: Create a binary variable for income,</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>income <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>income <span class="sc">==</span> <span class="st">"&gt;50K"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>income <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>income)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>and change all character variables to factors.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>df[, character_vars] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(df[, character_vars], as.factor)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the full dataframe at this point.</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS(df, file = "posts/classification_adult_data/data/df_adult_edited.rds")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Create the train and test datasets.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define train and test data indices</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_train) </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the number of rows in the test data to each row number of the training data in order to generate and index for the rows of the test data frame.</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_test))<span class="sc">+</span> <span class="fu">nrow</span>(df_train) </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train and test datasets</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>df_train <span class="ot">&lt;-</span> df[train, ]</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>df_test <span class="ot">&lt;-</span> df[test, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="analysis" class="level2">
<h2 class="anchored" data-anchor-id="analysis">Analysis</h2>
<p>I decided not to address the class-imbalance in these initial analyses. Due to the class imbalance I expect that the models may have low sensitivity, or in other words, struggle to correctly identify the minority class (in this case where income &gt; 50K). I will therefore explicitly compare the sensitivity between the different models.</p>
<p>Since the data contain a traning and test dataset, I decided to use the validation set approach for cross-validation. Thus, for each of the analyses, I fit the model on the training data and assess the model’s performance on the test data.</p>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h3>
<p>I first fit a logistic regression model, including all the variables in the dataset. There are some variables that have a significant influence on whether a person’s annual income is above $50K per year.</p>
<p>The variable <code>education_num</code> has a high variable inflation factor (VIF). It is likely highly correlated with the factor variable <code>education</code>. This variable is removed in subsequent analyses.</p>
<p>After removing the <code>education_num</code> variable, <code>education</code> becomes significant. The <code>workclass</code> variable does not seem to have a significant influence on the outcome. A Chi<sup>2</sup> test also reveals a significant association between the variables <code>workclass</code> and <code>occupation</code>. I remove this variable to see if it would improve the prediction model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Models</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Model 1 (formula 1 = f1): include all variables</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># R by default assigns the higher factor level as the positive class</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>glmf1 <span class="ot">&lt;-</span> income <span class="sc">~</span> .</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>fit_glmf1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(glmf1, <span class="at">data =</span> df_train, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the summary</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_glmf1)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the function alias to see if there may be collinearities in the data. It looks like there are none.</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="fu">alias</span>(fit_glmf1)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># The variance inflation factor of education_num is very high. I will remove education_num for subsequent analyses</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit_glmf1)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Model 2</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Based on AUC and precision, this model is the best of the logistic regression models</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>glmf2 <span class="ot">&lt;-</span> income <span class="sc">~</span> . <span class="sc">-</span>education_num </span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>fit_glmf2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(glmf2, <span class="at">data =</span> df_train, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>summary_glmf2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit_glmf2)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Looking at the variance inflation factor, it looks like there is no more problematic multicollinearity, since none of the adjusted VIF factors are above 5. Although there could be moderate multicollinearity between the variables relationship, marital_status and sex.</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit_glmf2)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at independence between workclass and occupation variables.</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="co"># It could be worth dropping one of these variables, as the Chi-square test shows significant association between them.</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(<span class="fu">table</span>(df_train<span class="sc">$</span>workclass, df_train<span class="sc">$</span>occupation))</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Model 3</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>glmf3 <span class="ot">&lt;-</span> income <span class="sc">~</span> . <span class="sc">-</span>education_num <span class="sc">-</span>workclass </span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>fit_glmf3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(glmf3, <span class="at">data =</span> df_train, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_glmf3)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit_glmf3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Make predictions using logistic regression Model 2 and Model 3 and determine model performance in the test data.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the probabilities using the logistic regression models</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>probs_glmf2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glmf2, <span class="at">newdata =</span> df_test, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>probs_glmf3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glmf3, <span class="at">newdata =</span> df_test, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Predict the class based on the calculated probabilities</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set predicted class to "&gt;50K" for observations with probabilities greater than 0.5</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>pred_glmf2 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">"0"</span>, <span class="dv">16281</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>pred_glmf2[probs_glmf2 <span class="sc">&gt;</span> <span class="fl">0.5</span>] <span class="ot">&lt;-</span> <span class="st">"1"</span> </span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred_glmf2, df_test<span class="sc">$</span>income)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>pred_glmf3 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">"0"</span>, <span class="dv">16281</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>pred_glmf3[probs_glmf3 <span class="sc">&gt;</span> <span class="fl">0.5</span>] <span class="ot">&lt;-</span> <span class="st">"1"</span> </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred_glmf3, df_test<span class="sc">$</span>income)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Create confusion matrices to determine accuracy, sensitivity etc.</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>confmatrix_glmf2 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">table</span>(pred_glmf2, df_test<span class="sc">$</span>income), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>confmatrix_glmf3 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">table</span>(pred_glmf3, df_test<span class="sc">$</span>income), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract different metrics for model performance</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Specificity = TN/(TN + FP)</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy = TP + TN/(TP + TN + FP + FN)</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Precision = TP/(TP + FP)</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Precision is given as "Pos Pred Value" in the caret package</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>specificity_glmf2 <span class="ot">&lt;-</span> confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>sensitivity_glmf2 <span class="ot">&lt;-</span> confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>]</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>accuracy_glmf2 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_glmf2<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>precision_glmf2 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>specificity_glmf3 <span class="ot">&lt;-</span> confmatrix_glmf3<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>accuracy_glmf3 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_glmf3<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>precision_glmf3 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_glmf3<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the area under the curve</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a><span class="co"># The predicted outcome must be numeric</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(df_test<span class="sc">$</span>income)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>roc_glmf2 <span class="ot">&lt;-</span> <span class="fu">roc</span>(y, probs_glmf2)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>auc_glmf2 <span class="ot">&lt;-</span> roc_glmf2<span class="sc">$</span>auc</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>roc_glmf3 <span class="ot">&lt;-</span> <span class="fu">roc</span>(y, probs_glmf3)</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>auc_glmf3 <span class="ot">&lt;-</span> roc_glmf3<span class="sc">$</span>auc</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Quick comparison between the AUC and precision of the two models.</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2 show the best model performance.</span></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(auc_glmf2, auc_glmf3))</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>], confmatrix_glmf3<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]))</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the prediction function from the ROCR package to create a prediction object. This will be used later to create an ROC graph</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a><span class="co"># tpr = true positive rate, fpr = false positive rate</span></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>pred_object_glmf2 <span class="ot">&lt;-</span> <span class="fu">prediction</span>(probs_glmf2, df_test<span class="sc">$</span>income)</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>perf_glmf2 <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_glmf2, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>auc_glmf2 <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_glmf2, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Take a look at which coefficients are most important for making the prediction.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the coefficients of model 2</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients (includes estimates, standard errors, etc.) for model 2</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># To order the coefficients by their absolute estimate size:</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>coefficients_glmf2 <span class="ot">&lt;-</span> summary_glmf2<span class="sc">$</span>coefficients</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>ordered_by_estimate <span class="ot">&lt;-</span> coefficients_glmf2[<span class="fu">order</span>(<span class="fu">abs</span>(coefficients_glmf2[, <span class="st">"Estimate"</span>]), <span class="at">decreasing =</span> <span class="cn">TRUE</span>), ]</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataframe of variable names and estimates</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the original estimates, not absolute values</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>importance_glmf2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">rownames</span>(ordered_by_estimate),  </span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">Estimate =</span> ordered_by_estimate[, <span class="st">"Estimate"</span>]  </span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the intercept from the dataframe</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset to the top 20 estimates (after removing intercept)</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>importance_glmf2_no_intercept <span class="ot">&lt;-</span> importance_glmf2[<span class="fu">rownames</span>(importance_glmf2) <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, ]</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>importance_glmf2_top20 <span class="ot">&lt;-</span> importance_glmf2_no_intercept[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, ]</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 20 absolute largest estimates</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Flip coordinates to make the plot horizontal</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>importance_plot_glm <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(importance_glmf2_top20, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="fu">abs</span>(Estimate)), <span class="at">y =</span> Estimate)) <span class="sc">+</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="fu">aes</span>(<span class="at">fill =</span> <span class="fu">ifelse</span>(Estimate <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>))) <span class="sc">+</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span>  </span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Logistic Regression Variable Importance"</span>,</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Variables"</span>,</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Coefficient Estimates"</span>) <span class="sc">+</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Define custom colors for positive (blue) and negative (orange)</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Negative"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>, <span class="st">"Positive"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>      <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="ridge-regression" class="level3">
<h3 class="anchored" data-anchor-id="ridge-regression">Ridge Regression</h3>
<p>I suspect that there may still be some correlated features in the data, such as <code>relationship</code> and <code>marital_status</code>. I use Ridge regression to distribute the weight more evenly across the features. The goal of this exercise is to determine which model will give the best prediction accuracy. Thus, model simplicity is not the biggest concern.</p>
<p>To do Ridge regression the data needs to be converted to a model matrix.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a model matrix using the model.matrix() function, which converts factors into dummy variables and represent all predictor variables in a matrix format.</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model.matrix() is used to one-hot encode categorical variables - i.e. each category for each categorical variable becomes a binary variable coded 0/1.</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the intercept, because model.matrix() by default includes an intercept column.</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>matrix_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(income <span class="sc">~</span> . <span class="sc">-</span><span class="dv">1</span> <span class="sc">-</span>education_num, <span class="at">data =</span> df_train)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> df_train<span class="sc">$</span>income</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>matrix_test <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(income <span class="sc">~</span> . <span class="sc">-</span><span class="dv">1</span> <span class="sc">-</span>education_num, <span class="at">data =</span> df_test)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">&lt;-</span> df_test<span class="sc">$</span>income</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>I do cross-validation to determine the best Lambda value for training the model. The trained model is used to make predictions in the test data. I decide to use the lambda that gives the minimum binomial deviance.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression (alpha = 0 means Ridge in glmnet)</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>fit_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(matrix_train, <span class="at">y =</span> y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a summary of the model</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_ridge)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use cross-validation to find the best lambda (regularization parameter)</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(matrix_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the cross-validation results</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv_ridge)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Results of cross-validation to find the best lambda for the ridge regression model.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the best lambda that minimizes the cross-validated error</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>best_lambda <span class="ot">&lt;-</span> cv_ridge<span class="sc">$</span>lambda.min</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Refit the model using the best lambda</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>fit_ridge_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(matrix_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> best_lambda)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>probs_ridge_best <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_ridge_best, matrix_test, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert probabilities to class predictions.</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>pred_ridge <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(probs_ridge_best <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Create a confusion matrix to evaluate peformance</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>confmatrix_ridge <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">table</span>(pred_ridge, y_test), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract performance metrics</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>specificity_ridge <span class="ot">&lt;-</span> confmatrix_ridge<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>sensitivity_ridge <span class="ot">&lt;-</span> confmatrix_ridge<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>]</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>accuracy_ridge <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_ridge<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>precision_ridge <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_ridge<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the prediction function from the ROCR package to create a prediction object. This will be used later to create an ROC graph</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="co"># tpr = true positive rate, fpr = false positive rate</span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the AUC (Area Under the Curve)</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>pred_object_ridge <span class="ot">&lt;-</span> <span class="fu">prediction</span>(probs_ridge_best, df_test<span class="sc">$</span>income)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>perf_ridge <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_ridge, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>auc_ridge <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_ridge, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>I determine the importance of the variables in this model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients for plotting variable importance</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients for the best lambda</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>coefficients_ridge <span class="ot">&lt;-</span> <span class="fu">coef</span>(fit_ridge_best, <span class="at">s =</span> best_lambda)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the coefficient matrix to a data frame for easier plotting</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">as.matrix</span>(coefficients_ridge))</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_df<span class="sc">$</span>Variable <span class="ot">&lt;-</span> <span class="fu">rownames</span>(coefficients_ridge_df)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(coefficients_ridge_df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Coefficient"</span>, <span class="st">"Variable"</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the intercept from the plot (optional)</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_df <span class="ot">&lt;-</span> coefficients_ridge_df[coefficients_ridge_df<span class="sc">$</span>Variable <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, ]</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the data frame by the absolute value of the coefficients and select the top 20</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_top_20 <span class="ot">&lt;-</span> coefficients_ridge_df <span class="sc">%&gt;%</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(<span class="fu">abs</span>(Coefficient))) <span class="sc">%&gt;%</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">20</span>)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the top 20 coefficients for Ridge regression</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>importance_plot_ridge <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(coefficients_ridge_top_20, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="fu">abs</span>(Coefficient)), <span class="at">y =</span> Coefficient)) <span class="sc">+</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="fu">aes</span>(<span class="at">fill =</span> <span class="fu">ifelse</span>(Coefficient <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>))) <span class="sc">+</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Ridge Regression Variable Importance"</span>,</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Variables"</span>, <span class="at">y =</span> <span class="st">"Coefficient"</span>) <span class="sc">+</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Negative"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>, <span class="st">"Positive"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="xgboost" class="level3">
<h3 class="anchored" data-anchor-id="xgboost">XGBoost</h3>
<p>XGBoost is a tree-based algorithm and therefore should not be particularly sensitive to collinear features.</p>
<p>XGBoost requires numerical inputs so I use the model matrices created for <a href="#ridge-regression">Ridge Regression</a> to create a DMatrix, which is XGBoost’s optimized data structure.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a training and test label for the outcome variable</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>y_train_label <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(df_train<span class="sc">$</span>income)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>y_test_label <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(df_test<span class="sc">$</span>income)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the data to DMatrix, which is XGBoost's optimized data structure</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>train_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> matrix_train, <span class="at">label =</span> y_train_label)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>test_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> matrix_test, <span class="at">label =</span> y_test_label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For this XGBoost model I choose parameters that should provide a good balance between model complexity and regularization. I am not going to use time on tuning this model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the XGBoost parameters</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">booster =</span> <span class="st">"gbtree"</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"binary:logistic"</span>,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">eta =</span> <span class="fl">0.1</span>,  <span class="co"># learning rate</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="dv">6</span>,</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> <span class="dv">1</span>,</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">subsample =</span> <span class="fl">0.8</span>,</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">colsample_bytree =</span> <span class="fl">0.8</span>,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">eval_metric =</span> <span class="st">"error"</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Prevent the output from being printed in the rendered html document by using invisible()</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>({</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>  fit_xgb1 <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">params =</span> params, </span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> train_xgb, </span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">100</span>, </span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">watchlist =</span> <span class="fu">list</span>(<span class="at">train =</span> train_xgb, <span class="at">eval =</span> test_xgb), </span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">early_stopping_rounds =</span> <span class="dv">10</span>,</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">print_every_n =</span> <span class="dv">10</span></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Make predictions using the XGBoost model and determine model performance.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Make predictions</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>probs_xgb1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_xgb1, <span class="at">newdata =</span> test_xgb)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>pred_xgb1 <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(probs_xgb1 <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix to obtain model performance</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Recap: sensitivity is the recall for the positive class</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Recap: specificity is the recall for the negative class</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>confmatrix_xgb1 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(pred_xgb1), <span class="fu">factor</span>(y_test_label), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>sensitivity_xgb1 <span class="ot">&lt;-</span> confmatrix_xgb1<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>] </span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>specificity_xgb1 <span class="ot">&lt;-</span> confmatrix_xgb1<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>] </span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>precision_xgb1 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_xgb1<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the prediction function from the ROCR package to create a prediction object. This will be used later to create an ROC graph</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co"># tpr = true positive rate, fpr = false positive rate</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the AUC (Area Under the Curve)</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>pred_object_xgb <span class="ot">&lt;-</span> <span class="fu">prediction</span>(probs_xgb1, y_test_label)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>perf_xgb <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_xgb, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>auc_xgb <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_xgb, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>As for the other models, I determine the importance of the different variables.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>importance_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.importance</span>(<span class="at">feature_names =</span> <span class="fu">colnames</span>(train_xgb), <span class="at">model =</span> fit_xgb1)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare a plot of the top 20 most important features</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This function (with a ggplot-backend) performs 1-D clustering of the importance values.</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Clusters with similar importance values get the same bar colours.</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>importance_plot_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.ggplot.importance</span>(<span class="at">importance_matrix =</span> importance_xgb,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">top_n =</span> <span class="dv">20</span>, <span class="at">n_clusters =</span> <span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">theme</span>(</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>                      <span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>                      <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>                      <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>                                                <span class="co">#, face = "bold") </span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>                      ) <span class="sc">+</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">ggtitle</span>(<span class="st">"XGBoost Variable Importance"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="support-vector-classifier" class="level3">
<h3 class="anchored" data-anchor-id="support-vector-classifier">Support Vector Classifier</h3>
<p>The support vector classifier (SVC) is a method that constructs a set of hyperplanes that separates the training data into two classes.</p>
<p>I perform regularization by adjusting the cost tuning parameter (C), which allows changing the number and severity of the violations to the margin. A smaller C value increases the margin size by allowing more violations, while a larger C value reduces the margin and penalizes misclassifications more severely.</p>
<!-- How the C (cost) tuning parameter works: -->
<!-- C Tuning Parameter: The C parameter in SVC controls the degree of regularization. -->
<!-- A small C (more regularization) allows a larger margin with more violations (misclassified points), making the classifier more tolerant to errors, which can help generalize better. -->
<!-- A large C (less regularization) reduces the margin and penalizes violations more severely, making the classifier focus on correctly classifying all points, which may lead to overfitting. -->
<p>The best value for the cost tuning parameter (C) is determined through cross validation.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the SVC model at different values of the C tuning parameter</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># I use the built-in tune() function in the e1071 library</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train an SVM model with a linear kernel - corresponds to support vector classifier (SVC) </span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># I explicitly remove education_num from the data frame, since with first run, just defining the formula, is not sufficient for excluding it from the model.</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove education_num from the dataset before fitting the model</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>df_train_svc <span class="ot">&lt;-</span> df_train[, <span class="sc">!</span><span class="fu">colnames</span>(df_train) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"education_num"</span>)]</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>df_test_svc <span class="ot">&lt;-</span> df_test[, <span class="sc">!</span><span class="fu">colnames</span>(df_test) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"education_num"</span>)]</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>svcf1 <span class="ot">&lt;-</span> income <span class="sc">~</span>. </span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Script for finding the optimal cost parameter through cross validation</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>tune_svc <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, svcf1, <span class="at">data =</span> df_train, <span class="at">kernel =</span> <span class="st">"linear"</span>,</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>)))</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="co"># This computation takes quite some time, so I am saving the results.</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS(tune_svc, file = "posts/classification_adult_data/tune_svc.rds")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Since the cross-validation for different values takes quite some time, I save the results for easy loading. I use the cost value that gives the smallest error for subsequent predictions.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#~/Dropbox/Projects/Portfolio/posts/classification_adult_data</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co">#tune_svc &lt;- readRDS("/Users/Dropbox/Projects/Portfolio/posts/classification_adult_data/tune_svc.rds")</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>tune_svc <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"tune_svc_new.rds"</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_svc)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the best model</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>bestmod_svc <span class="ot">&lt;-</span> tune_svc<span class="sc">$</span>best.model</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class and probabilities using the best model</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>pred_svc <span class="ot">&lt;-</span> <span class="fu">predict</span>(bestmod_svc, df_test, <span class="at">decision.values =</span> <span class="cn">TRUE</span>)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Create confusion matrix to evaluate the model's performance</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract accuracy, precision, sensitivity and specificity</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>confmatrix_svc <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_svc, df_test<span class="sc">$</span>income, <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>accuracy_svc <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_svc<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>precision_svc <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_svc<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>specificity_svc <span class="ot">&lt;-</span> confmatrix_svc<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>sensitivity_svc <span class="ot">&lt;-</span> confmatrix_svc<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>]</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="do">## ROC curve</span></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the decision values (distance from the decision boundary)</span></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>decision_values_svc <span class="ot">&lt;-</span> <span class="fu">attributes</span>(pred_svc)<span class="sc">$</span>decision.values</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Use ROCR package to plot the ROC curve</span></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a prediction object using decision values and true labels</span></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the negative of the fitted decision values so that negative values correspond to class 1 and the positive values to class 2 (ISLR p. 395).</span></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the AUC (Area Under the Curve)</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>pred_object_svc <span class="ot">&lt;-</span> <span class="fu">prediction</span>(<span class="sc">-</span>decision_values_svc, y_test_label)</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>perf_svc <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_svc, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>auc_svc <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_svc, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Determine the importance of the variables in this model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the importance of the different variables in the model</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients (weights) and support vectors, multiplying them gives the final coefficient (weight) for each feature in the decision boundary.</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>svc_coefficients <span class="ot">&lt;-</span> <span class="fu">t</span>(bestmod_svc<span class="sc">$</span>coefs) <span class="sc">%*%</span> bestmod_svc<span class="sc">$</span>SV</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients and the names</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>svc_coeff_values <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(svc_coefficients)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>variable_names <span class="ot">&lt;-</span> <span class="fu">dimnames</span>(svc_coefficients)[[<span class="dv">2</span>]]</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the names and coefficients into a named vector</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember that in this case:</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Positive coefficients (in the output from my SVM model) will push the decision toward the negative class.</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Negative coefficients will push the decision toward the positive class.</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>svc_coefficients_named <span class="ot">&lt;-</span> <span class="fu">setNames</span>(<span class="sc">-</span>svc_coeff_values, variable_names)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the coefficients by their absolute values, keeping the names intact</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the top 20 largest estimates (based on absolute values)</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>svc_coefficients_ordered <span class="ot">&lt;-</span> svc_coefficients_named[<span class="fu">order</span>(<span class="fu">abs</span>(svc_coefficients_named), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)]</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>importance_svc_top20 <span class="ot">&lt;-</span> svc_coefficients_ordered[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the named vector of top 20 into a dataframe for plotting</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>importance_svc_top20 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">names</span>(importance_svc_top20),</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">Coefficient =</span> importance_svc_top20</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a bar plot with the actual values (not the absolute ones)</span></span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>importance_plot_svc <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(importance_svc_top20, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="fu">abs</span>(Coefficient)), <span class="at">y =</span> Coefficient)) <span class="sc">+</span></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="fu">aes</span>(<span class="at">fill =</span> <span class="fu">ifelse</span>(Coefficient <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>))) <span class="sc">+</span></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"SVC Variable Importance"</span>, </span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>         <span class="at">x =</span> <span class="st">"Variables"</span>, </span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>         <span class="at">y =</span> <span class="st">"Coefficient Value"</span>) <span class="sc">+</span></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Negative"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>, <span class="st">"Positive"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>The main goal of this post is to identify which statistical method performs best in predicting annual income in the adult census data. Nevertheless, I still think it is interesting to look at the variable importance across the different methods.</p>
<p>The figures below show the 20 most important variables in the different methods used.</p>
<div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>importance_plot_glm</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>importance_plot_ridge</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>importance_plot_xgb</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>importance_plot_svc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-38-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-38-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-38-4.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
<p>The figure below shows the ROC curves and AUC for the different methods.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_svc, <span class="at">col =</span> <span class="st">"green"</span>, <span class="at">main =</span> <span class="st">"ROC Curves"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_xgb, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_glmf2, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_ridge, <span class="at">col =</span> <span class="st">"purple"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend to the plot with AUC values</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>,</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="fu">paste</span>(<span class="st">"SVM AUC:"</span>, <span class="fu">round</span>(auc_svc, <span class="dv">3</span>)),</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">paste</span>(<span class="st">"XGBoost AUC:"</span>, <span class="fu">round</span>(auc_xgb, <span class="dv">3</span>)),</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">paste</span>(<span class="st">"Logistic Regression AUC:"</span>, <span class="fu">round</span>(auc_glmf2, <span class="dv">3</span>)),</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">paste</span>(<span class="st">"Ridge Regression AUC:"</span>, <span class="fu">round</span>(auc_ridge, <span class="dv">3</span>))),</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"green"</span>, <span class="st">"red"</span>, <span class="st">"blue"</span>, <span class="st">"purple"</span>),</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_adult_data_files/figure-html/unnamed-chunk-39-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The following table shows the performance of the different methods used as measured by the metrics sensitivity, specificity and precision.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect all the results in a data frame</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Method =</span> <span class="fu">c</span>(<span class="st">"Logistic Regression"</span>, <span class="st">"Ridge Regression"</span>, <span class="st">"XGBoost"</span>, <span class="st">"Support Vector Classifier"</span>),</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sensitivity =</span> <span class="fu">c</span>(sensitivity_glmf2, sensitivity_ridge, sensitivity_xgb1, sensitivity_svc),</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">Specificity =</span> <span class="fu">c</span>(specificity_glmf2, specificity_ridge, specificity_xgb1, specificity_svc),</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Precision =</span> <span class="fu">c</span>(precision_glmf2, precision_ridge, precision_xgb1, precision_svc)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Order the results by Precision in descending order</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> results[<span class="fu">order</span>(<span class="sc">-</span>results<span class="sc">$</span>Precision), ]</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the values for a clean display</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>results[, <span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="fu">round</span>(results[, <span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>], <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>Whereas logistic regression can give important information for making inferences about the importance of the different variables and their effects, XGBoost and the SVC are not designed for making direct inferences. XGBoost and the SVC are primarily predictive models that focus on maximizing predictive accuracy.</p>
</section>
<section id="skills" class="level2">
<h2 class="anchored" data-anchor-id="skills">Skills</h2>
<p>Statistical learning, machine learning, R-programming, Tableau and data visualization.</p>
<p>References:<br>
Becker, Barry and Kohavi, Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.<br>
James, G., Witten, D., Hastie, T. og Tibshirani, R. 2021. An Introduction to Statistical Learning (ISLR): with Applications in R. Available at: https://link.springer.com/content/pdf/10. 1007/978-1-0716-1418-1.pdf.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb49" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Statistical Learning: classification problem"</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Izel Fourie Sørensen"</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-10-01"</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [code, analysis]</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "pexels-karolina-grabowska-edited.jpg"</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">results =</span> <span class="st">'hide'</span>)</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Goal</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>In this post I use different statistical models for predicting whether a person's annual income will exceed \$50K a year based on data in the "Census Income" data set.</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap-location: bottom</span></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Photo by Karolina Kaboompics"</span></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: left</span></span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a><span class="co">#| out.width: 30%</span></span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a><span class="co">#| out.height: 30%</span></span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"~/Dropbox/GitHub/Portfolio/posts/classification_adult_data/pexels-karolina-grabowska-edited.jpg"</span>)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the necessary libraries</span></span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a><span class="co"># car: VIF factor</span></span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a><span class="co"># caret: confusionMatrix</span></span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a><span class="co"># naniar: missing values</span></span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a><span class="co"># e1071: support vector classifier</span></span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a><span class="co"># ROCR: ROC curves</span></span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(<span class="st">"qgg"</span>, <span class="st">"corrplot"</span>, <span class="st">"ggplot2"</span>, <span class="st">"tidyr"</span>, <span class="st">"mlbench"</span>, </span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>               <span class="st">"readr"</span>, <span class="st">"data.table"</span>, <span class="st">"naniar"</span>, <span class="st">"car"</span>, <span class="st">"caret"</span>,</span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a>                <span class="st">"xgboost"</span>, <span class="st">"dplyr"</span>, <span class="st">"Matrix"</span>, <span class="st">"e1071"</span>, <span class="st">"glmnet"</span>,</span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a>               <span class="st">"ROCR"</span>, <span class="st">"pROC"</span>)</span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- https://www.pexels.com/photo/hands-holding-us-dollar-bills-4968656/ --&gt;</span></span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a>The focus of this post is to determine which statistical model gives the best prediction of this binary outcome. I will compare logistic regression, XGBoost and the Support Vector Classifier models for their accuracy and precision in predicting the outcome. I will not spend a lot of time on explorative data analysis.</span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb49-56"><a href="#cb49-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-57"><a href="#cb49-57" aria-hidden="true" tabindex="-1"></a>The data as well as information about the dataset can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://archive.ics.uci.edu/dataset/2/adult)</span>.</span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the Adult data</span></span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">"https://archive.ics.uci.edu/static/public/2/adult.zip"</span></span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a>destfile <span class="ot">&lt;-</span> <span class="fu">tempfile</span>()</span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a>exdir <span class="ot">&lt;-</span> <span class="fu">tempdir</span>()</span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(<span class="at">url=</span>url, <span class="at">destfile=</span>destfile)</span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a><span class="fu">unzip</span>(destfile, <span class="at">exdir=</span>exdir)</span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a><span class="co"># I am not showing the output of the following. It is not pretty to look at, but helps me identify the files downloaded in the zipped file.</span></span>
<span id="cb49-71"><a href="#cb49-71" aria-hidden="true" tabindex="-1"></a><span class="fu">list.files</span>(exdir, <span class="at">full.names =</span> <span class="cn">TRUE</span>) </span>
<span id="cb49-72"><a href="#cb49-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a>The Adult data comes in a train and test set, so no need to partition the data into a training and test set.</span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-79"><a href="#cb49-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-80"><a href="#cb49-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the train and test data sets</span></span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a>df_train <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="fu">file.path</span>(exdir,<span class="st">"adult.data"</span>), <span class="at">data.table=</span><span class="cn">FALSE</span>)</span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a>df_test <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="fu">file.path</span>(exdir,<span class="st">"adult.test"</span>), <span class="at">skip=</span><span class="dv">1</span>, <span class="at">data.table=</span><span class="cn">FALSE</span>)</span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-84"><a href="#cb49-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-85"><a href="#cb49-85" aria-hidden="true" tabindex="-1"></a>The variable names are given in the description of the data on the website. I added them manually.</span>
<span id="cb49-86"><a href="#cb49-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-89"><a href="#cb49-89" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-90"><a href="#cb49-90" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb49-91"><a href="#cb49-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-92"><a href="#cb49-92" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(df_train) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"workclass"</span>, <span class="st">"fnlwgt"</span>, <span class="st">"education"</span>, <span class="st">"education_num"</span>,</span>
<span id="cb49-93"><a href="#cb49-93" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"marital_status"</span>, <span class="st">"occupation"</span>, <span class="st">"relationship"</span>, <span class="st">"race"</span>,</span>
<span id="cb49-94"><a href="#cb49-94" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"sex"</span>, <span class="st">"capital_gain"</span>, <span class="st">"capital_loss"</span>, <span class="st">"hours_per_week"</span>,</span>
<span id="cb49-95"><a href="#cb49-95" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"native_country"</span>, <span class="st">"income"</span>)</span>
<span id="cb49-96"><a href="#cb49-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-97"><a href="#cb49-97" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(df_test) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"age"</span>, <span class="st">"workclass"</span>, <span class="st">"fnlwgt"</span>, <span class="st">"education"</span>, <span class="st">"education_num"</span>,</span>
<span id="cb49-98"><a href="#cb49-98" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"marital_status"</span>, <span class="st">"occupation"</span>, <span class="st">"relationship"</span>, <span class="st">"race"</span>,</span>
<span id="cb49-99"><a href="#cb49-99" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"sex"</span>, <span class="st">"capital_gain"</span>, <span class="st">"capital_loss"</span>, <span class="st">"hours_per_week"</span>,</span>
<span id="cb49-100"><a href="#cb49-100" aria-hidden="true" tabindex="-1"></a>                         <span class="st">"native_country"</span>, <span class="st">"income"</span>)</span>
<span id="cb49-101"><a href="#cb49-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-102"><a href="#cb49-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the structure of the data frames</span></span>
<span id="cb49-103"><a href="#cb49-103" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df_train)</span>
<span id="cb49-104"><a href="#cb49-104" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df_test)</span>
<span id="cb49-105"><a href="#cb49-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-106"><a href="#cb49-106" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df_train)</span>
<span id="cb49-107"><a href="#cb49-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-108"><a href="#cb49-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean the test dataset income column by remove the "."</span></span>
<span id="cb49-109"><a href="#cb49-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Use fixed=TRUE to treat it as a literal string, and not a regular expression:</span></span>
<span id="cb49-110"><a href="#cb49-110" aria-hidden="true" tabindex="-1"></a>df_test<span class="sc">$</span>income <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"."</span>, <span class="st">""</span>, df_test<span class="sc">$</span>income, <span class="at">fixed=</span><span class="cn">TRUE</span>)</span>
<span id="cb49-111"><a href="#cb49-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-112"><a href="#cb49-112" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-113"><a href="#cb49-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-114"><a href="#cb49-114" aria-hidden="true" tabindex="-1"></a>The data consists of <span class="in">`r ncol(df)`</span> variables. The training data consists of <span class="in">`r nrow(df_train)`</span> observations and the test data of <span class="in">`r nrow(df_test)`</span>.</span>
<span id="cb49-115"><a href="#cb49-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-116"><a href="#cb49-116" aria-hidden="true" tabindex="-1"></a>Here is a quick view of what the data looks like.</span>
<span id="cb49-117"><a href="#cb49-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-120"><a href="#cb49-120" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-121"><a href="#cb49-121" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: markup</span></span>
<span id="cb49-122"><a href="#cb49-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-123"><a href="#cb49-123" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_train)</span>
<span id="cb49-124"><a href="#cb49-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-125"><a href="#cb49-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-126"><a href="#cb49-126" aria-hidden="true" tabindex="-1"></a>Although I didn't want to spend too much time on explorative data analysis, I couldn't help looking at the income difference between men and women. (Just for fun I created the graph in Tableau.) The figure shows exactly what I expected: that the proportion of females earning more than \$50K would be much lower than the proportion of males. The figure also shows that there is class imbalance in the dataset, since the class income <span class="sc">\&gt;</span> \$50K occurs less frequent than the other.</span>
<span id="cb49-127"><a href="#cb49-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-128"><a href="#cb49-128" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb49-129"><a href="#cb49-129" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;div class='tableauPlaceholder' id='viz1728455966947' style='position: relative'&gt;&lt;noscript&gt;&lt;a href='#'&gt;&lt;img alt='Percentage of males and females that earned more or less than $50,000 in 1994. ' src='https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;Bo&amp;#47;Book1_17279468755020&amp;#47;Sheet2&amp;#47;1_rss.png' style='border: none' /&gt;&lt;/a&gt;&lt;/noscript&gt;&lt;object class='tableauViz'  style='display:none;'&gt;&lt;param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /&gt; &lt;param name='embed_code_version' value='3' /&gt; &lt;param name='site_root' value='' /&gt;&lt;param name='name' value='Book1_17279468755020&amp;#47;Sheet2' /&gt;&lt;param name='tabs' value='no' /&gt;&lt;param name='toolbar' value='yes' /&gt;&lt;param name='static_image' value='https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;Bo&amp;#47;Book1_17279468755020&amp;#47;Sheet2&amp;#47;1.png' /&gt; &lt;param name='animate_transition' value='yes' /&gt;&lt;param name='display_static_image' value='yes' /&gt;&lt;param name='display_spinner' value='yes' /&gt;&lt;param name='display_overlay' value='yes' /&gt;&lt;param name='display_count' value='yes' /&gt;&lt;param name='language' value='en-GB' /&gt;&lt;param name='filter' value='publish=yes' /&gt;&lt;/object&gt;&lt;/div&gt;                </span></span>
<span id="cb49-130"><a href="#cb49-130" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;script type='text/javascript'&gt;                    </span></span>
<span id="cb49-131"><a href="#cb49-131" aria-hidden="true" tabindex="-1"></a><span class="in">var divElement = document.getElementById('viz1728455966947');</span></span>
<span id="cb49-132"><a href="#cb49-132" aria-hidden="true" tabindex="-1"></a><span class="in">var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                &lt;/script&gt;</span></span>
<span id="cb49-133"><a href="#cb49-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-134"><a href="#cb49-134" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-135"><a href="#cb49-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-136"><a href="#cb49-136" aria-hidden="true" tabindex="-1"></a>The figure below shows the distribution of ages for people earning more or less than \$50,000 per year. There is a clear shift towards older age for earning above \$50K. The curve suggests that in 1994 middle-aged individuals were more likely to have incomes above \$50K.</span>
<span id="cb49-137"><a href="#cb49-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-140"><a href="#cb49-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-141"><a href="#cb49-141" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 4</span></span>
<span id="cb49-142"><a href="#cb49-142" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb49-143"><a href="#cb49-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-144"><a href="#cb49-144" aria-hidden="true" tabindex="-1"></a><span class="co"># dev.off()</span></span>
<span id="cb49-145"><a href="#cb49-145" aria-hidden="true" tabindex="-1"></a><span class="co"># To see the age range where people are more likely to fall into a particular income bracket:</span></span>
<span id="cb49-146"><a href="#cb49-146" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_train, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">fill =</span> income)) <span class="sc">+</span></span>
<span id="cb49-147"><a href="#cb49-147" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb49-148"><a href="#cb49-148" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb49-149"><a href="#cb49-149" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Age distribution by income group"</span>,</span>
<span id="cb49-150"><a href="#cb49-150" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> <span class="st">"Age"</span>, <span class="at">Y =</span> <span class="st">"Density"</span></span>
<span id="cb49-151"><a href="#cb49-151" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-152"><a href="#cb49-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"&lt;=50K"</span> <span class="ot">=</span> <span class="st">"#4E7AA7"</span>, <span class="st">"&gt;50K"</span> <span class="ot">=</span> <span class="st">"#E49343"</span>)) <span class="sc">+</span></span>
<span id="cb49-153"><a href="#cb49-153" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-154"><a href="#cb49-154" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb49-155"><a href="#cb49-155" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>()</span>
<span id="cb49-156"><a href="#cb49-156" aria-hidden="true" tabindex="-1"></a>    <span class="co">#,</span></span>
<span id="cb49-157"><a href="#cb49-157" aria-hidden="true" tabindex="-1"></a>    <span class="co">#panel.grid.minor = element_blank()</span></span>
<span id="cb49-158"><a href="#cb49-158" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb49-159"><a href="#cb49-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Age Distribution by Income Group"</span>,</span>
<span id="cb49-160"><a href="#cb49-160" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age"</span>, <span class="at">y =</span> <span class="st">"Density"</span>)</span>
<span id="cb49-161"><a href="#cb49-161" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-162"><a href="#cb49-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-163"><a href="#cb49-163" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data preparation</span></span>
<span id="cb49-164"><a href="#cb49-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-165"><a href="#cb49-165" aria-hidden="true" tabindex="-1"></a>Join the training and test datasets so that I can edit the datasets as a whole.</span>
<span id="cb49-166"><a href="#cb49-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-169"><a href="#cb49-169" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-170"><a href="#cb49-170" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the character variables to factors</span></span>
<span id="cb49-171"><a href="#cb49-171" aria-hidden="true" tabindex="-1"></a>df  <span class="ot">&lt;-</span> <span class="fu">rbind</span>(df_train,df_test)</span>
<span id="cb49-172"><a href="#cb49-172" aria-hidden="true" tabindex="-1"></a>character_vars <span class="ot">&lt;-</span> <span class="fu">lapply</span>(df, class) <span class="sc">==</span> <span class="st">"character"</span></span>
<span id="cb49-173"><a href="#cb49-173" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df)</span>
<span id="cb49-174"><a href="#cb49-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-175"><a href="#cb49-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-176"><a href="#cb49-176" aria-hidden="true" tabindex="-1"></a>Even though the website mentions missing data, there does not seem to be missing data in the train and test sets.</span>
<span id="cb49-177"><a href="#cb49-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-180"><a href="#cb49-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-181"><a href="#cb49-181" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb49-182"><a href="#cb49-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-183"><a href="#cb49-183" aria-hidden="true" tabindex="-1"></a><span class="co"># colSums(is.na(df_train))</span></span>
<span id="cb49-184"><a href="#cb49-184" aria-hidden="true" tabindex="-1"></a><span class="co"># colSums(is.na(df_test))</span></span>
<span id="cb49-185"><a href="#cb49-185" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(df))</span>
<span id="cb49-186"><a href="#cb49-186" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-187"><a href="#cb49-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-188"><a href="#cb49-188" aria-hidden="true" tabindex="-1"></a>There are duplicates in the data, but it is not unlikely that more than one person could have the same entries for the different variables in this dataset.</span>
<span id="cb49-189"><a href="#cb49-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-192"><a href="#cb49-192" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-193"><a href="#cb49-193" aria-hidden="true" tabindex="-1"></a><span class="fu">any</span>(<span class="fu">duplicated</span>(df))</span>
<span id="cb49-194"><a href="#cb49-194" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">duplicated</span>(df) <span class="sc">|</span> <span class="fu">duplicated</span>(df, <span class="at">fromLast =</span> <span class="cn">TRUE</span>))</span>
<span id="cb49-195"><a href="#cb49-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-196"><a href="#cb49-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-197"><a href="#cb49-197" aria-hidden="true" tabindex="-1"></a>Look at the distribution of the numerical columns by making box plots.</span>
<span id="cb49-198"><a href="#cb49-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-201"><a href="#cb49-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-202"><a href="#cb49-202" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numeric colummns</span></span>
<span id="cb49-203"><a href="#cb49-203" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a boxplot of each numeric column</span></span>
<span id="cb49-204"><a href="#cb49-204" aria-hidden="true" tabindex="-1"></a>numeric_columns <span class="ot">&lt;-</span> df[, <span class="fu">sapply</span>(df, is.numeric)]</span>
<span id="cb49-205"><a href="#cb49-205" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))  </span>
<span id="cb49-206"><a href="#cb49-206" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(<span class="fu">names</span>(numeric_columns), <span class="cf">function</span>(col) {</span>
<span id="cb49-207"><a href="#cb49-207" aria-hidden="true" tabindex="-1"></a>  <span class="fu">boxplot</span>(numeric_columns[[col]], <span class="at">main =</span> col, <span class="at">ylab =</span> col)</span>
<span id="cb49-208"><a href="#cb49-208" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb49-209"><a href="#cb49-209" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb49-210"><a href="#cb49-210" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-211"><a href="#cb49-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-212"><a href="#cb49-212" aria-hidden="true" tabindex="-1"></a>A closer look at the distribution of the capital_gain and capital_loss variables shows that their distribution is highly skewed to the right, with the majority of observations being zero. There are a few extreme outliers that are inflating the mean.</span>
<span id="cb49-213"><a href="#cb49-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-216"><a href="#cb49-216" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-217"><a href="#cb49-217" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: markup</span></span>
<span id="cb49-218"><a href="#cb49-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-219"><a href="#cb49-219" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of capital_gain and capital_loss</span></span>
<span id="cb49-220"><a href="#cb49-220" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Summary of Capital Gain:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb49-221"><a href="#cb49-221" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df<span class="sc">$</span>capital_gain)</span>
<span id="cb49-222"><a href="#cb49-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-223"><a href="#cb49-223" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Summary of Capital Loss:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb49-224"><a href="#cb49-224" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df<span class="sc">$</span>capital_loss)</span>
<span id="cb49-225"><a href="#cb49-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-226"><a href="#cb49-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-227"><a href="#cb49-227" aria-hidden="true" tabindex="-1"></a>I decide to change these variables to binary variables instead, where any value above zero is assigned "1" otherwise "0".</span>
<span id="cb49-228"><a href="#cb49-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-231"><a href="#cb49-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-232"><a href="#cb49-232" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_gain <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>capital_gain <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb49-233"><a href="#cb49-233" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_gain <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>capital_gain)</span>
<span id="cb49-234"><a href="#cb49-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-235"><a href="#cb49-235" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_loss <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>capital_loss <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb49-236"><a href="#cb49-236" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>capital_loss <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>capital_loss)</span>
<span id="cb49-237"><a href="#cb49-237" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-238"><a href="#cb49-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-239"><a href="#cb49-239" aria-hidden="true" tabindex="-1"></a>I check for covariance between variables (correlated features) and variables with very low variance (below 1e-5).</span>
<span id="cb49-240"><a href="#cb49-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-241"><a href="#cb49-241" aria-hidden="true" tabindex="-1"></a>The highest correlation is observed between <span class="in">`hours_per_week`</span> and <span class="in">`education_num`</span> with a value of <span class="in">`r round(cor(df_train$hours_per_week, df_train$education_num, use = "complete.obs"), 3)`</span>.</span>
<span id="cb49-242"><a href="#cb49-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-245"><a href="#cb49-245" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-246"><a href="#cb49-246" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Heatmap of correlations between numerical variables.</span></span>
<span id="cb49-247"><a href="#cb49-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-248"><a href="#cb49-248" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at covariance between variables</span></span>
<span id="cb49-249"><a href="#cb49-249" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numerical features in the training data</span></span>
<span id="cb49-250"><a href="#cb49-250" aria-hidden="true" tabindex="-1"></a>num_vars <span class="ot">&lt;-</span> <span class="fu">sapply</span>(df_train, is.numeric)</span>
<span id="cb49-251"><a href="#cb49-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-252"><a href="#cb49-252" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute correlation matrix for numerical variables</span></span>
<span id="cb49-253"><a href="#cb49-253" aria-hidden="true" tabindex="-1"></a><span class="co"># None of the variables appear to be highly correlated</span></span>
<span id="cb49-254"><a href="#cb49-254" aria-hidden="true" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(df_train[, num_vars], <span class="at">use =</span> <span class="st">"complete.obs"</span>)</span>
<span id="cb49-255"><a href="#cb49-255" aria-hidden="true" tabindex="-1"></a>cor_matrix</span>
<span id="cb49-256"><a href="#cb49-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-257"><a href="#cb49-257" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize correlations with a heatmap</span></span>
<span id="cb49-258"><a href="#cb49-258" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(cor_matrix, <span class="at">method =</span> <span class="st">"color"</span>, <span class="at">tl.cex =</span> <span class="fl">0.7</span>)</span>
<span id="cb49-259"><a href="#cb49-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-260"><a href="#cb49-260" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at the variance of numerical variables</span></span>
<span id="cb49-261"><a href="#cb49-261" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate variance for each numeric column</span></span>
<span id="cb49-262"><a href="#cb49-262" aria-hidden="true" tabindex="-1"></a>variances <span class="ot">&lt;-</span> <span class="fu">apply</span>(df_train[, num_vars], <span class="dv">2</span>, var)</span>
<span id="cb49-263"><a href="#cb49-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-264"><a href="#cb49-264" aria-hidden="true" tabindex="-1"></a><span class="co"># Find features with low variance (e.g., variance close to 0)</span></span>
<span id="cb49-265"><a href="#cb49-265" aria-hidden="true" tabindex="-1"></a>low_variance_features <span class="ot">&lt;-</span> <span class="fu">names</span>(variances[variances <span class="sc">&lt;</span> <span class="fl">1e-5</span>])</span>
<span id="cb49-266"><a href="#cb49-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-267"><a href="#cb49-267" aria-hidden="true" tabindex="-1"></a><span class="do">## Check for variables consisting of a single value</span></span>
<span id="cb49-268"><a href="#cb49-268" aria-hidden="true" tabindex="-1"></a>single_value_check <span class="ot">&lt;-</span> <span class="fu">sapply</span>(df_train, <span class="cf">function</span>(x) <span class="fu">length</span>(<span class="fu">unique</span>(x)) <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb49-269"><a href="#cb49-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-270"><a href="#cb49-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-271"><a href="#cb49-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-272"><a href="#cb49-272" aria-hidden="true" tabindex="-1"></a>The number of observations for the different outcomes for predictor variable classes is important. It is preferable to have at least 10 observations for each level of the outcome variable for each of the predictor variable categories.</span>
<span id="cb49-273"><a href="#cb49-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-276"><a href="#cb49-276" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-277"><a href="#cb49-277" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at the number of observations for different classes of categorical variables</span></span>
<span id="cb49-278"><a href="#cb49-278" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(df_train[,character_vars], table)</span>
<span id="cb49-279"><a href="#cb49-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-280"><a href="#cb49-280" aria-hidden="true" tabindex="-1"></a><span class="co"># Create contingency tables between each character variable and df$income</span></span>
<span id="cb49-281"><a href="#cb49-281" aria-hidden="true" tabindex="-1"></a>character_vars_pred <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">names</span>(df_train)[<span class="fu">sapply</span>(df_train, is.character)], <span class="st">"income"</span>)</span>
<span id="cb49-282"><a href="#cb49-282" aria-hidden="true" tabindex="-1"></a>contingency_tables <span class="ot">&lt;-</span> <span class="fu">lapply</span>(character_vars_pred, <span class="cf">function</span>(var) {</span>
<span id="cb49-283"><a href="#cb49-283" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>(df_train[[var]], df_train<span class="sc">$</span>income)</span>
<span id="cb49-284"><a href="#cb49-284" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb49-285"><a href="#cb49-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-286"><a href="#cb49-286" aria-hidden="true" tabindex="-1"></a><span class="co"># Name each table by the character variable</span></span>
<span id="cb49-287"><a href="#cb49-287" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(contingency_tables) <span class="ot">&lt;-</span> character_vars_pred</span>
<span id="cb49-288"><a href="#cb49-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-289"><a href="#cb49-289" aria-hidden="true" tabindex="-1"></a><span class="co"># View the contingency tables</span></span>
<span id="cb49-290"><a href="#cb49-290" aria-hidden="true" tabindex="-1"></a>contingency_tables</span>
<span id="cb49-291"><a href="#cb49-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-292"><a href="#cb49-292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-293"><a href="#cb49-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-294"><a href="#cb49-294" aria-hidden="true" tabindex="-1"></a>I decide to combine some of the categories for the variables workclass, education, occupation and native_country. These variables are edited as follows:</span>
<span id="cb49-295"><a href="#cb49-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-296"><a href="#cb49-296" aria-hidden="true" tabindex="-1"></a><span class="in">`workclass`</span>  </span>
<span id="cb49-297"><a href="#cb49-297" aria-hidden="true" tabindex="-1"></a>Working Without_pay and Never_worked is very unlikely to result in an income above <span class="sc">\&gt;</span>50K. I am merging these categories with the category "?".</span>
<span id="cb49-298"><a href="#cb49-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-301"><a href="#cb49-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-302"><a href="#cb49-302" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>workclass[df<span class="sc">$</span>workclass <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Without-pay"</span>, <span class="st">"Never-worked"</span>)] <span class="ot">&lt;-</span> <span class="st">"?"</span> </span>
<span id="cb49-303"><a href="#cb49-303" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>income, df<span class="sc">$</span>workclass)</span>
<span id="cb49-304"><a href="#cb49-304" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-305"><a href="#cb49-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-306"><a href="#cb49-306" aria-hidden="true" tabindex="-1"></a><span class="in">`education`</span>  </span>
<span id="cb49-307"><a href="#cb49-307" aria-hidden="true" tabindex="-1"></a>Add Preschool, and the other grades up to 9th grade and call it pre-primary-school.</span>
<span id="cb49-308"><a href="#cb49-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-311"><a href="#cb49-311" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-312"><a href="#cb49-312" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>education[df<span class="sc">$</span>education <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Preschool"</span>, <span class="st">"1st-4th"</span>, <span class="st">"5th-6th"</span>, <span class="st">"7th-8th"</span>, <span class="st">"9th"</span>)] <span class="ot">&lt;-</span> <span class="st">"pre-primary-school"</span></span>
<span id="cb49-313"><a href="#cb49-313" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>income, df<span class="sc">$</span>education)</span>
<span id="cb49-314"><a href="#cb49-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-315"><a href="#cb49-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-316"><a href="#cb49-316" aria-hidden="true" tabindex="-1"></a><span class="in">`occupation`</span>  </span>
<span id="cb49-317"><a href="#cb49-317" aria-hidden="true" tabindex="-1"></a>Move Armed-Forces and Priv-house-serv to "?"</span>
<span id="cb49-318"><a href="#cb49-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-321"><a href="#cb49-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-322"><a href="#cb49-322" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>occupation[df<span class="sc">$</span>occupation <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Armed-Forces"</span>, <span class="st">"Priv-house-serv"</span>)] <span class="ot">&lt;-</span> <span class="st">"?"</span></span>
<span id="cb49-323"><a href="#cb49-323" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df<span class="sc">$</span>income, df<span class="sc">$</span>occupation)</span>
<span id="cb49-324"><a href="#cb49-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-325"><a href="#cb49-325" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-326"><a href="#cb49-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-327"><a href="#cb49-327" aria-hidden="true" tabindex="-1"></a><span class="in">`native_country`</span>  </span>
<span id="cb49-328"><a href="#cb49-328" aria-hidden="true" tabindex="-1"></a>Move all countries with that have less than 10 observations in the training data to a new category called "Other".</span>
<span id="cb49-329"><a href="#cb49-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-332"><a href="#cb49-332" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-333"><a href="#cb49-333" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a contingency table of income and native_country</span></span>
<span id="cb49-334"><a href="#cb49-334" aria-hidden="true" tabindex="-1"></a>contingency_table_native_country <span class="ot">&lt;-</span> <span class="fu">table</span>(df_train<span class="sc">$</span>income, df_train<span class="sc">$</span>native_country)</span>
<span id="cb49-335"><a href="#cb49-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-336"><a href="#cb49-336" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the native_country categories with fewer than 10 observations in any income row</span></span>
<span id="cb49-337"><a href="#cb49-337" aria-hidden="true" tabindex="-1"></a>low_count_country <span class="ot">&lt;-</span> <span class="fu">apply</span>(contingency_table_native_country, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">any</span>(x <span class="sc">&lt;</span> <span class="dv">10</span>))</span>
<span id="cb49-338"><a href="#cb49-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-339"><a href="#cb49-339" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the countries that meet the condition</span></span>
<span id="cb49-340"><a href="#cb49-340" aria-hidden="true" tabindex="-1"></a>low_count_countries <span class="ot">&lt;-</span> <span class="fu">names</span>(low_count_country[low_count_country])</span>
<span id="cb49-341"><a href="#cb49-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-342"><a href="#cb49-342" aria-hidden="true" tabindex="-1"></a><span class="co"># Move all low count countries to a new category "other"</span></span>
<span id="cb49-343"><a href="#cb49-343" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>native_country[df<span class="sc">$</span>native_country <span class="sc">%in%</span> low_count_countries] <span class="ot">&lt;-</span> <span class="st">"Other"</span></span>
<span id="cb49-344"><a href="#cb49-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-345"><a href="#cb49-345" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-346"><a href="#cb49-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-347"><a href="#cb49-347" aria-hidden="true" tabindex="-1"></a>Other minor adjustments: Create a binary variable for income,</span>
<span id="cb49-348"><a href="#cb49-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-351"><a href="#cb49-351" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-352"><a href="#cb49-352" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>income <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>income <span class="sc">==</span> <span class="st">"&gt;50K"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb49-353"><a href="#cb49-353" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>income <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>income)</span>
<span id="cb49-354"><a href="#cb49-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-355"><a href="#cb49-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-356"><a href="#cb49-356" aria-hidden="true" tabindex="-1"></a>and change all character variables to factors.</span>
<span id="cb49-357"><a href="#cb49-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-360"><a href="#cb49-360" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-361"><a href="#cb49-361" aria-hidden="true" tabindex="-1"></a>df[, character_vars] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(df[, character_vars], as.factor)</span>
<span id="cb49-362"><a href="#cb49-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-363"><a href="#cb49-363" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the full dataframe at this point.</span></span>
<span id="cb49-364"><a href="#cb49-364" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS(df, file = "posts/classification_adult_data/data/df_adult_edited.rds")</span></span>
<span id="cb49-365"><a href="#cb49-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-366"><a href="#cb49-366" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-367"><a href="#cb49-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-368"><a href="#cb49-368" aria-hidden="true" tabindex="-1"></a>Create the train and test datasets.</span>
<span id="cb49-369"><a href="#cb49-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-372"><a href="#cb49-372" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-373"><a href="#cb49-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Define train and test data indices</span></span>
<span id="cb49-374"><a href="#cb49-374" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_train) </span>
<span id="cb49-375"><a href="#cb49-375" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the number of rows in the test data to each row number of the training data in order to generate and index for the rows of the test data frame.</span></span>
<span id="cb49-376"><a href="#cb49-376" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_test))<span class="sc">+</span> <span class="fu">nrow</span>(df_train) </span>
<span id="cb49-377"><a href="#cb49-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-378"><a href="#cb49-378" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train and test datasets</span></span>
<span id="cb49-379"><a href="#cb49-379" aria-hidden="true" tabindex="-1"></a>df_train <span class="ot">&lt;-</span> df[train, ]</span>
<span id="cb49-380"><a href="#cb49-380" aria-hidden="true" tabindex="-1"></a>df_test <span class="ot">&lt;-</span> df[test, ]</span>
<span id="cb49-381"><a href="#cb49-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-382"><a href="#cb49-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-383"><a href="#cb49-383" aria-hidden="true" tabindex="-1"></a><span class="fu">## Analysis</span></span>
<span id="cb49-384"><a href="#cb49-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-385"><a href="#cb49-385" aria-hidden="true" tabindex="-1"></a>I decided not to address the class-imbalance in these initial analyses. Due to the class imbalance I expect that the models may have low sensitivity, or in other words, struggle to correctly identify the minority class (in this case where income <span class="sc">\&gt;</span> 50K). I will therefore explicitly compare the sensitivity between the different models.</span>
<span id="cb49-386"><a href="#cb49-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-387"><a href="#cb49-387" aria-hidden="true" tabindex="-1"></a>Since the data contain a traning and test dataset, I decided to use the validation set approach for cross-validation. Thus, for each of the analyses, I fit the model on the training data and assess the model's performance on the test data.</span>
<span id="cb49-388"><a href="#cb49-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-389"><a href="#cb49-389" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistic Regression {#logistic-regression}</span></span>
<span id="cb49-390"><a href="#cb49-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-391"><a href="#cb49-391" aria-hidden="true" tabindex="-1"></a>I first fit a logistic regression model, including all the variables in the dataset. There are some variables that have a significant influence on whether a person's annual income is above \$50K per year.</span>
<span id="cb49-392"><a href="#cb49-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-393"><a href="#cb49-393" aria-hidden="true" tabindex="-1"></a>The variable <span class="in">`education_num`</span> has a high variable inflation factor (VIF). It is likely highly correlated with the factor variable <span class="in">`education`</span>. This variable is removed in subsequent analyses.</span>
<span id="cb49-394"><a href="#cb49-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-395"><a href="#cb49-395" aria-hidden="true" tabindex="-1"></a>After removing the <span class="in">`education_num`</span> variable, <span class="in">`education`</span> becomes significant. The <span class="in">`workclass`</span> variable does not seem to have a significant influence on the outcome. A Chi^2^ test also reveals a significant association between the variables <span class="in">`workclass`</span> and <span class="in">`occupation`</span>. I remove this variable to see if it would improve the prediction model.</span>
<span id="cb49-396"><a href="#cb49-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-399"><a href="#cb49-399" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-400"><a href="#cb49-400" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb49-401"><a href="#cb49-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-402"><a href="#cb49-402" aria-hidden="true" tabindex="-1"></a><span class="do">### Models</span></span>
<span id="cb49-403"><a href="#cb49-403" aria-hidden="true" tabindex="-1"></a><span class="do">## Model 1 (formula 1 = f1): include all variables</span></span>
<span id="cb49-404"><a href="#cb49-404" aria-hidden="true" tabindex="-1"></a><span class="co"># R by default assigns the higher factor level as the positive class</span></span>
<span id="cb49-405"><a href="#cb49-405" aria-hidden="true" tabindex="-1"></a>glmf1 <span class="ot">&lt;-</span> income <span class="sc">~</span> .</span>
<span id="cb49-406"><a href="#cb49-406" aria-hidden="true" tabindex="-1"></a>fit_glmf1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(glmf1, <span class="at">data =</span> df_train, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb49-407"><a href="#cb49-407" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the summary</span></span>
<span id="cb49-408"><a href="#cb49-408" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_glmf1)</span>
<span id="cb49-409"><a href="#cb49-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-410"><a href="#cb49-410" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the function alias to see if there may be collinearities in the data. It looks like there are none.</span></span>
<span id="cb49-411"><a href="#cb49-411" aria-hidden="true" tabindex="-1"></a><span class="fu">alias</span>(fit_glmf1)</span>
<span id="cb49-412"><a href="#cb49-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-413"><a href="#cb49-413" aria-hidden="true" tabindex="-1"></a><span class="co"># The variance inflation factor of education_num is very high. I will remove education_num for subsequent analyses</span></span>
<span id="cb49-414"><a href="#cb49-414" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit_glmf1)</span>
<span id="cb49-415"><a href="#cb49-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-416"><a href="#cb49-416" aria-hidden="true" tabindex="-1"></a><span class="do">## Model 2</span></span>
<span id="cb49-417"><a href="#cb49-417" aria-hidden="true" tabindex="-1"></a><span class="co"># Based on AUC and precision, this model is the best of the logistic regression models</span></span>
<span id="cb49-418"><a href="#cb49-418" aria-hidden="true" tabindex="-1"></a>glmf2 <span class="ot">&lt;-</span> income <span class="sc">~</span> . <span class="sc">-</span>education_num </span>
<span id="cb49-419"><a href="#cb49-419" aria-hidden="true" tabindex="-1"></a>fit_glmf2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(glmf2, <span class="at">data =</span> df_train, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb49-420"><a href="#cb49-420" aria-hidden="true" tabindex="-1"></a>summary_glmf2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit_glmf2)</span>
<span id="cb49-421"><a href="#cb49-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-422"><a href="#cb49-422" aria-hidden="true" tabindex="-1"></a><span class="co"># Looking at the variance inflation factor, it looks like there is no more problematic multicollinearity, since none of the adjusted VIF factors are above 5. Although there could be moderate multicollinearity between the variables relationship, marital_status and sex.</span></span>
<span id="cb49-423"><a href="#cb49-423" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit_glmf2)</span>
<span id="cb49-424"><a href="#cb49-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-425"><a href="#cb49-425" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at independence between workclass and occupation variables.</span></span>
<span id="cb49-426"><a href="#cb49-426" aria-hidden="true" tabindex="-1"></a><span class="co"># It could be worth dropping one of these variables, as the Chi-square test shows significant association between them.</span></span>
<span id="cb49-427"><a href="#cb49-427" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(<span class="fu">table</span>(df_train<span class="sc">$</span>workclass, df_train<span class="sc">$</span>occupation))</span>
<span id="cb49-428"><a href="#cb49-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-429"><a href="#cb49-429" aria-hidden="true" tabindex="-1"></a><span class="do">## Model 3</span></span>
<span id="cb49-430"><a href="#cb49-430" aria-hidden="true" tabindex="-1"></a>glmf3 <span class="ot">&lt;-</span> income <span class="sc">~</span> . <span class="sc">-</span>education_num <span class="sc">-</span>workclass </span>
<span id="cb49-431"><a href="#cb49-431" aria-hidden="true" tabindex="-1"></a>fit_glmf3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(glmf3, <span class="at">data =</span> df_train, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb49-432"><a href="#cb49-432" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_glmf3)</span>
<span id="cb49-433"><a href="#cb49-433" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit_glmf3)</span>
<span id="cb49-434"><a href="#cb49-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-435"><a href="#cb49-435" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-436"><a href="#cb49-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-437"><a href="#cb49-437" aria-hidden="true" tabindex="-1"></a>Make predictions using logistic regression Model 2 and Model 3 and determine model performance in the test data.</span>
<span id="cb49-438"><a href="#cb49-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-441"><a href="#cb49-441" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-442"><a href="#cb49-442" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the probabilities using the logistic regression models</span></span>
<span id="cb49-443"><a href="#cb49-443" aria-hidden="true" tabindex="-1"></a>probs_glmf2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glmf2, <span class="at">newdata =</span> df_test, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb49-444"><a href="#cb49-444" aria-hidden="true" tabindex="-1"></a>probs_glmf3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glmf3, <span class="at">newdata =</span> df_test, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb49-445"><a href="#cb49-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-446"><a href="#cb49-446" aria-hidden="true" tabindex="-1"></a><span class="do">## Predict the class based on the calculated probabilities</span></span>
<span id="cb49-447"><a href="#cb49-447" aria-hidden="true" tabindex="-1"></a><span class="co"># Set predicted class to "&gt;50K" for observations with probabilities greater than 0.5</span></span>
<span id="cb49-448"><a href="#cb49-448" aria-hidden="true" tabindex="-1"></a>pred_glmf2 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">"0"</span>, <span class="dv">16281</span>)</span>
<span id="cb49-449"><a href="#cb49-449" aria-hidden="true" tabindex="-1"></a>pred_glmf2[probs_glmf2 <span class="sc">&gt;</span> <span class="fl">0.5</span>] <span class="ot">&lt;-</span> <span class="st">"1"</span> </span>
<span id="cb49-450"><a href="#cb49-450" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred_glmf2, df_test<span class="sc">$</span>income)</span>
<span id="cb49-451"><a href="#cb49-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-452"><a href="#cb49-452" aria-hidden="true" tabindex="-1"></a>pred_glmf3 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">"0"</span>, <span class="dv">16281</span>)</span>
<span id="cb49-453"><a href="#cb49-453" aria-hidden="true" tabindex="-1"></a>pred_glmf3[probs_glmf3 <span class="sc">&gt;</span> <span class="fl">0.5</span>] <span class="ot">&lt;-</span> <span class="st">"1"</span> </span>
<span id="cb49-454"><a href="#cb49-454" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred_glmf3, df_test<span class="sc">$</span>income)</span>
<span id="cb49-455"><a href="#cb49-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-456"><a href="#cb49-456" aria-hidden="true" tabindex="-1"></a><span class="do">## Create confusion matrices to determine accuracy, sensitivity etc.</span></span>
<span id="cb49-457"><a href="#cb49-457" aria-hidden="true" tabindex="-1"></a>confmatrix_glmf2 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">table</span>(pred_glmf2, df_test<span class="sc">$</span>income), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb49-458"><a href="#cb49-458" aria-hidden="true" tabindex="-1"></a>confmatrix_glmf3 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">table</span>(pred_glmf3, df_test<span class="sc">$</span>income), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb49-459"><a href="#cb49-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-460"><a href="#cb49-460" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract different metrics for model performance</span></span>
<span id="cb49-461"><a href="#cb49-461" aria-hidden="true" tabindex="-1"></a><span class="co"># Specificity = TN/(TN + FP)</span></span>
<span id="cb49-462"><a href="#cb49-462" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy = TP + TN/(TP + TN + FP + FN)</span></span>
<span id="cb49-463"><a href="#cb49-463" aria-hidden="true" tabindex="-1"></a><span class="co"># Precision = TP/(TP + FP)</span></span>
<span id="cb49-464"><a href="#cb49-464" aria-hidden="true" tabindex="-1"></a><span class="co"># Precision is given as "Pos Pred Value" in the caret package</span></span>
<span id="cb49-465"><a href="#cb49-465" aria-hidden="true" tabindex="-1"></a>specificity_glmf2 <span class="ot">&lt;-</span> confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb49-466"><a href="#cb49-466" aria-hidden="true" tabindex="-1"></a>sensitivity_glmf2 <span class="ot">&lt;-</span> confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>]</span>
<span id="cb49-467"><a href="#cb49-467" aria-hidden="true" tabindex="-1"></a>accuracy_glmf2 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_glmf2<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb49-468"><a href="#cb49-468" aria-hidden="true" tabindex="-1"></a>precision_glmf2 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb49-469"><a href="#cb49-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-470"><a href="#cb49-470" aria-hidden="true" tabindex="-1"></a>specificity_glmf3 <span class="ot">&lt;-</span> confmatrix_glmf3<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb49-471"><a href="#cb49-471" aria-hidden="true" tabindex="-1"></a>accuracy_glmf3 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_glmf3<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb49-472"><a href="#cb49-472" aria-hidden="true" tabindex="-1"></a>precision_glmf3 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_glmf3<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb49-473"><a href="#cb49-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-474"><a href="#cb49-474" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the area under the curve</span></span>
<span id="cb49-475"><a href="#cb49-475" aria-hidden="true" tabindex="-1"></a><span class="co"># The predicted outcome must be numeric</span></span>
<span id="cb49-476"><a href="#cb49-476" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(df_test<span class="sc">$</span>income)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb49-477"><a href="#cb49-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-478"><a href="#cb49-478" aria-hidden="true" tabindex="-1"></a>roc_glmf2 <span class="ot">&lt;-</span> <span class="fu">roc</span>(y, probs_glmf2)</span>
<span id="cb49-479"><a href="#cb49-479" aria-hidden="true" tabindex="-1"></a>auc_glmf2 <span class="ot">&lt;-</span> roc_glmf2<span class="sc">$</span>auc</span>
<span id="cb49-480"><a href="#cb49-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-481"><a href="#cb49-481" aria-hidden="true" tabindex="-1"></a>roc_glmf3 <span class="ot">&lt;-</span> <span class="fu">roc</span>(y, probs_glmf3)</span>
<span id="cb49-482"><a href="#cb49-482" aria-hidden="true" tabindex="-1"></a>auc_glmf3 <span class="ot">&lt;-</span> roc_glmf3<span class="sc">$</span>auc</span>
<span id="cb49-483"><a href="#cb49-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-484"><a href="#cb49-484" aria-hidden="true" tabindex="-1"></a><span class="co"># Quick comparison between the AUC and precision of the two models.</span></span>
<span id="cb49-485"><a href="#cb49-485" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2 show the best model performance.</span></span>
<span id="cb49-486"><a href="#cb49-486" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(auc_glmf2, auc_glmf3))</span>
<span id="cb49-487"><a href="#cb49-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-488"><a href="#cb49-488" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">c</span>(confmatrix_glmf2<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>], confmatrix_glmf3<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]))</span>
<span id="cb49-489"><a href="#cb49-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-490"><a href="#cb49-490" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the prediction function from the ROCR package to create a prediction object. This will be used later to create an ROC graph</span></span>
<span id="cb49-491"><a href="#cb49-491" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb49-492"><a href="#cb49-492" aria-hidden="true" tabindex="-1"></a><span class="co"># tpr = true positive rate, fpr = false positive rate</span></span>
<span id="cb49-493"><a href="#cb49-493" aria-hidden="true" tabindex="-1"></a>pred_object_glmf2 <span class="ot">&lt;-</span> <span class="fu">prediction</span>(probs_glmf2, df_test<span class="sc">$</span>income)</span>
<span id="cb49-494"><a href="#cb49-494" aria-hidden="true" tabindex="-1"></a>perf_glmf2 <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_glmf2, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb49-495"><a href="#cb49-495" aria-hidden="true" tabindex="-1"></a>auc_glmf2 <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_glmf2, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span>
<span id="cb49-496"><a href="#cb49-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-497"><a href="#cb49-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-498"><a href="#cb49-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-499"><a href="#cb49-499" aria-hidden="true" tabindex="-1"></a>Take a look at which coefficients are most important for making the prediction.</span>
<span id="cb49-500"><a href="#cb49-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-503"><a href="#cb49-503" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-504"><a href="#cb49-504" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the coefficients of model 2</span></span>
<span id="cb49-505"><a href="#cb49-505" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients (includes estimates, standard errors, etc.) for model 2</span></span>
<span id="cb49-506"><a href="#cb49-506" aria-hidden="true" tabindex="-1"></a><span class="co"># To order the coefficients by their absolute estimate size:</span></span>
<span id="cb49-507"><a href="#cb49-507" aria-hidden="true" tabindex="-1"></a>coefficients_glmf2 <span class="ot">&lt;-</span> summary_glmf2<span class="sc">$</span>coefficients</span>
<span id="cb49-508"><a href="#cb49-508" aria-hidden="true" tabindex="-1"></a>ordered_by_estimate <span class="ot">&lt;-</span> coefficients_glmf2[<span class="fu">order</span>(<span class="fu">abs</span>(coefficients_glmf2[, <span class="st">"Estimate"</span>]), <span class="at">decreasing =</span> <span class="cn">TRUE</span>), ]</span>
<span id="cb49-509"><a href="#cb49-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-510"><a href="#cb49-510" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataframe of variable names and estimates</span></span>
<span id="cb49-511"><a href="#cb49-511" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the original estimates, not absolute values</span></span>
<span id="cb49-512"><a href="#cb49-512" aria-hidden="true" tabindex="-1"></a>importance_glmf2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb49-513"><a href="#cb49-513" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">rownames</span>(ordered_by_estimate),  </span>
<span id="cb49-514"><a href="#cb49-514" aria-hidden="true" tabindex="-1"></a>  <span class="at">Estimate =</span> ordered_by_estimate[, <span class="st">"Estimate"</span>]  </span>
<span id="cb49-515"><a href="#cb49-515" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-516"><a href="#cb49-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-517"><a href="#cb49-517" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the intercept from the dataframe</span></span>
<span id="cb49-518"><a href="#cb49-518" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset to the top 20 estimates (after removing intercept)</span></span>
<span id="cb49-519"><a href="#cb49-519" aria-hidden="true" tabindex="-1"></a>importance_glmf2_no_intercept <span class="ot">&lt;-</span> importance_glmf2[<span class="fu">rownames</span>(importance_glmf2) <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, ]</span>
<span id="cb49-520"><a href="#cb49-520" aria-hidden="true" tabindex="-1"></a>importance_glmf2_top20 <span class="ot">&lt;-</span> importance_glmf2_no_intercept[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, ]</span>
<span id="cb49-521"><a href="#cb49-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-522"><a href="#cb49-522" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 20 absolute largest estimates</span></span>
<span id="cb49-523"><a href="#cb49-523" aria-hidden="true" tabindex="-1"></a><span class="co"># Flip coordinates to make the plot horizontal</span></span>
<span id="cb49-524"><a href="#cb49-524" aria-hidden="true" tabindex="-1"></a>importance_plot_glm <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(importance_glmf2_top20, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="fu">abs</span>(Estimate)), <span class="at">y =</span> Estimate)) <span class="sc">+</span></span>
<span id="cb49-525"><a href="#cb49-525" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="fu">aes</span>(<span class="at">fill =</span> <span class="fu">ifelse</span>(Estimate <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>))) <span class="sc">+</span></span>
<span id="cb49-526"><a href="#cb49-526" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span>  </span>
<span id="cb49-527"><a href="#cb49-527" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Logistic Regression Variable Importance"</span>,</span>
<span id="cb49-528"><a href="#cb49-528" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Variables"</span>,</span>
<span id="cb49-529"><a href="#cb49-529" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Coefficient Estimates"</span>) <span class="sc">+</span></span>
<span id="cb49-530"><a href="#cb49-530" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-531"><a href="#cb49-531" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Define custom colors for positive (blue) and negative (orange)</span></span>
<span id="cb49-532"><a href="#cb49-532" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Negative"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>, <span class="st">"Positive"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb49-533"><a href="#cb49-533" aria-hidden="true" tabindex="-1"></a><span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb49-534"><a href="#cb49-534" aria-hidden="true" tabindex="-1"></a>      <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb49-535"><a href="#cb49-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-536"><a href="#cb49-536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-537"><a href="#cb49-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-538"><a href="#cb49-538" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ridge Regression {#ridge-regression}</span></span>
<span id="cb49-539"><a href="#cb49-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-540"><a href="#cb49-540" aria-hidden="true" tabindex="-1"></a>I suspect that there may still be some correlated features in the data, such as <span class="in">`relationship`</span> and <span class="in">`marital_status`</span>. I use Ridge regression to distribute the weight more evenly across the features. The goal of this exercise is to determine which model will give the best prediction accuracy. Thus, model simplicity is not the biggest concern.</span>
<span id="cb49-541"><a href="#cb49-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-542"><a href="#cb49-542" aria-hidden="true" tabindex="-1"></a>To do Ridge regression the data needs to be converted to a model matrix.</span>
<span id="cb49-543"><a href="#cb49-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-546"><a href="#cb49-546" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-547"><a href="#cb49-547" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a model matrix using the model.matrix() function, which converts factors into dummy variables and represent all predictor variables in a matrix format.</span></span>
<span id="cb49-548"><a href="#cb49-548" aria-hidden="true" tabindex="-1"></a><span class="co"># model.matrix() is used to one-hot encode categorical variables - i.e. each category for each categorical variable becomes a binary variable coded 0/1.</span></span>
<span id="cb49-549"><a href="#cb49-549" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the intercept, because model.matrix() by default includes an intercept column.</span></span>
<span id="cb49-550"><a href="#cb49-550" aria-hidden="true" tabindex="-1"></a>matrix_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(income <span class="sc">~</span> . <span class="sc">-</span><span class="dv">1</span> <span class="sc">-</span>education_num, <span class="at">data =</span> df_train)</span>
<span id="cb49-551"><a href="#cb49-551" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> df_train<span class="sc">$</span>income</span>
<span id="cb49-552"><a href="#cb49-552" aria-hidden="true" tabindex="-1"></a>matrix_test <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(income <span class="sc">~</span> . <span class="sc">-</span><span class="dv">1</span> <span class="sc">-</span>education_num, <span class="at">data =</span> df_test)</span>
<span id="cb49-553"><a href="#cb49-553" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">&lt;-</span> df_test<span class="sc">$</span>income</span>
<span id="cb49-554"><a href="#cb49-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-555"><a href="#cb49-555" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-556"><a href="#cb49-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-557"><a href="#cb49-557" aria-hidden="true" tabindex="-1"></a>I do cross-validation to determine the best Lambda value for training the model. The trained model is used to make predictions in the test data. I decide to use the lambda that gives the minimum binomial deviance.</span>
<span id="cb49-558"><a href="#cb49-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-561"><a href="#cb49-561" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-562"><a href="#cb49-562" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Results of cross-validation to find the best lambda for the ridge regression model.</span></span>
<span id="cb49-563"><a href="#cb49-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-564"><a href="#cb49-564" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression (alpha = 0 means Ridge in glmnet)</span></span>
<span id="cb49-565"><a href="#cb49-565" aria-hidden="true" tabindex="-1"></a>fit_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(matrix_train, <span class="at">y =</span> y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb49-566"><a href="#cb49-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-567"><a href="#cb49-567" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a summary of the model</span></span>
<span id="cb49-568"><a href="#cb49-568" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit_ridge)</span>
<span id="cb49-569"><a href="#cb49-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-570"><a href="#cb49-570" aria-hidden="true" tabindex="-1"></a><span class="co"># Use cross-validation to find the best lambda (regularization parameter)</span></span>
<span id="cb49-571"><a href="#cb49-571" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(matrix_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb49-572"><a href="#cb49-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-573"><a href="#cb49-573" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the cross-validation results</span></span>
<span id="cb49-574"><a href="#cb49-574" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv_ridge)</span>
<span id="cb49-575"><a href="#cb49-575" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-576"><a href="#cb49-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-579"><a href="#cb49-579" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-580"><a href="#cb49-580" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the best lambda that minimizes the cross-validated error</span></span>
<span id="cb49-581"><a href="#cb49-581" aria-hidden="true" tabindex="-1"></a>best_lambda <span class="ot">&lt;-</span> cv_ridge<span class="sc">$</span>lambda.min</span>
<span id="cb49-582"><a href="#cb49-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-583"><a href="#cb49-583" aria-hidden="true" tabindex="-1"></a><span class="co"># Refit the model using the best lambda</span></span>
<span id="cb49-584"><a href="#cb49-584" aria-hidden="true" tabindex="-1"></a>fit_ridge_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(matrix_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> best_lambda)</span>
<span id="cb49-585"><a href="#cb49-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-586"><a href="#cb49-586" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb49-587"><a href="#cb49-587" aria-hidden="true" tabindex="-1"></a>probs_ridge_best <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_ridge_best, matrix_test, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb49-588"><a href="#cb49-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-589"><a href="#cb49-589" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert probabilities to class predictions.</span></span>
<span id="cb49-590"><a href="#cb49-590" aria-hidden="true" tabindex="-1"></a>pred_ridge <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(probs_ridge_best <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb49-591"><a href="#cb49-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-592"><a href="#cb49-592" aria-hidden="true" tabindex="-1"></a><span class="do">## Create a confusion matrix to evaluate peformance</span></span>
<span id="cb49-593"><a href="#cb49-593" aria-hidden="true" tabindex="-1"></a>confmatrix_ridge <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">table</span>(pred_ridge, y_test), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb49-594"><a href="#cb49-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-595"><a href="#cb49-595" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract performance metrics</span></span>
<span id="cb49-596"><a href="#cb49-596" aria-hidden="true" tabindex="-1"></a>specificity_ridge <span class="ot">&lt;-</span> confmatrix_ridge<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb49-597"><a href="#cb49-597" aria-hidden="true" tabindex="-1"></a>sensitivity_ridge <span class="ot">&lt;-</span> confmatrix_ridge<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>]</span>
<span id="cb49-598"><a href="#cb49-598" aria-hidden="true" tabindex="-1"></a>accuracy_ridge <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_ridge<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb49-599"><a href="#cb49-599" aria-hidden="true" tabindex="-1"></a>precision_ridge <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_ridge<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb49-600"><a href="#cb49-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-601"><a href="#cb49-601" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the prediction function from the ROCR package to create a prediction object. This will be used later to create an ROC graph</span></span>
<span id="cb49-602"><a href="#cb49-602" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb49-603"><a href="#cb49-603" aria-hidden="true" tabindex="-1"></a><span class="co"># tpr = true positive rate, fpr = false positive rate</span></span>
<span id="cb49-604"><a href="#cb49-604" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the AUC (Area Under the Curve)</span></span>
<span id="cb49-605"><a href="#cb49-605" aria-hidden="true" tabindex="-1"></a>pred_object_ridge <span class="ot">&lt;-</span> <span class="fu">prediction</span>(probs_ridge_best, df_test<span class="sc">$</span>income)</span>
<span id="cb49-606"><a href="#cb49-606" aria-hidden="true" tabindex="-1"></a>perf_ridge <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_ridge, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb49-607"><a href="#cb49-607" aria-hidden="true" tabindex="-1"></a>auc_ridge <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_ridge, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span>
<span id="cb49-608"><a href="#cb49-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-609"><a href="#cb49-609" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-610"><a href="#cb49-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-611"><a href="#cb49-611" aria-hidden="true" tabindex="-1"></a>I determine the importance of the variables in this model.</span>
<span id="cb49-612"><a href="#cb49-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-615"><a href="#cb49-615" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-616"><a href="#cb49-616" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients for plotting variable importance</span></span>
<span id="cb49-617"><a href="#cb49-617" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients for the best lambda</span></span>
<span id="cb49-618"><a href="#cb49-618" aria-hidden="true" tabindex="-1"></a>coefficients_ridge <span class="ot">&lt;-</span> <span class="fu">coef</span>(fit_ridge_best, <span class="at">s =</span> best_lambda)</span>
<span id="cb49-619"><a href="#cb49-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-620"><a href="#cb49-620" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the coefficient matrix to a data frame for easier plotting</span></span>
<span id="cb49-621"><a href="#cb49-621" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">as.matrix</span>(coefficients_ridge))</span>
<span id="cb49-622"><a href="#cb49-622" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_df<span class="sc">$</span>Variable <span class="ot">&lt;-</span> <span class="fu">rownames</span>(coefficients_ridge_df)</span>
<span id="cb49-623"><a href="#cb49-623" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(coefficients_ridge_df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Coefficient"</span>, <span class="st">"Variable"</span>)</span>
<span id="cb49-624"><a href="#cb49-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-625"><a href="#cb49-625" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the intercept from the plot (optional)</span></span>
<span id="cb49-626"><a href="#cb49-626" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_df <span class="ot">&lt;-</span> coefficients_ridge_df[coefficients_ridge_df<span class="sc">$</span>Variable <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, ]</span>
<span id="cb49-627"><a href="#cb49-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-628"><a href="#cb49-628" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the data frame by the absolute value of the coefficients and select the top 20</span></span>
<span id="cb49-629"><a href="#cb49-629" aria-hidden="true" tabindex="-1"></a>coefficients_ridge_top_20 <span class="ot">&lt;-</span> coefficients_ridge_df <span class="sc">%&gt;%</span></span>
<span id="cb49-630"><a href="#cb49-630" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(<span class="fu">abs</span>(Coefficient))) <span class="sc">%&gt;%</span></span>
<span id="cb49-631"><a href="#cb49-631" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">20</span>)</span>
<span id="cb49-632"><a href="#cb49-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-633"><a href="#cb49-633" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the top 20 coefficients for Ridge regression</span></span>
<span id="cb49-634"><a href="#cb49-634" aria-hidden="true" tabindex="-1"></a>importance_plot_ridge <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(coefficients_ridge_top_20, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="fu">abs</span>(Coefficient)), <span class="at">y =</span> Coefficient)) <span class="sc">+</span></span>
<span id="cb49-635"><a href="#cb49-635" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="fu">aes</span>(<span class="at">fill =</span> <span class="fu">ifelse</span>(Coefficient <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>))) <span class="sc">+</span></span>
<span id="cb49-636"><a href="#cb49-636" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb49-637"><a href="#cb49-637" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Ridge Regression Variable Importance"</span>,</span>
<span id="cb49-638"><a href="#cb49-638" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Variables"</span>, <span class="at">y =</span> <span class="st">"Coefficient"</span>) <span class="sc">+</span></span>
<span id="cb49-639"><a href="#cb49-639" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-640"><a href="#cb49-640" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Negative"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>, <span class="st">"Positive"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb49-641"><a href="#cb49-641" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb49-642"><a href="#cb49-642" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb49-643"><a href="#cb49-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-644"><a href="#cb49-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-645"><a href="#cb49-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-646"><a href="#cb49-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-647"><a href="#cb49-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-648"><a href="#cb49-648" aria-hidden="true" tabindex="-1"></a><span class="fu">### XGBoost</span></span>
<span id="cb49-649"><a href="#cb49-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-650"><a href="#cb49-650" aria-hidden="true" tabindex="-1"></a>XGBoost is a tree-based algorithm and therefore should not be particularly sensitive to collinear features.</span>
<span id="cb49-651"><a href="#cb49-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-652"><a href="#cb49-652" aria-hidden="true" tabindex="-1"></a>XGBoost requires numerical inputs so I use the model matrices created for <span class="co">[</span><span class="ot">Ridge Regression</span><span class="co">](#ridge-regression)</span> to create a DMatrix, which is XGBoost's optimized data structure.</span>
<span id="cb49-653"><a href="#cb49-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-656"><a href="#cb49-656" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-657"><a href="#cb49-657" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb49-658"><a href="#cb49-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-659"><a href="#cb49-659" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a training and test label for the outcome variable</span></span>
<span id="cb49-660"><a href="#cb49-660" aria-hidden="true" tabindex="-1"></a>y_train_label <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(df_train<span class="sc">$</span>income)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb49-661"><a href="#cb49-661" aria-hidden="true" tabindex="-1"></a>y_test_label <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(df_test<span class="sc">$</span>income)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb49-662"><a href="#cb49-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-663"><a href="#cb49-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-664"><a href="#cb49-664" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the data to DMatrix, which is XGBoost's optimized data structure</span></span>
<span id="cb49-665"><a href="#cb49-665" aria-hidden="true" tabindex="-1"></a>train_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> matrix_train, <span class="at">label =</span> y_train_label)</span>
<span id="cb49-666"><a href="#cb49-666" aria-hidden="true" tabindex="-1"></a>test_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> matrix_test, <span class="at">label =</span> y_test_label)</span>
<span id="cb49-667"><a href="#cb49-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-668"><a href="#cb49-668" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-669"><a href="#cb49-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-670"><a href="#cb49-670" aria-hidden="true" tabindex="-1"></a>For this XGBoost model I choose parameters that should provide a good balance between model complexity and regularization. I am not going to use time on tuning this model.</span>
<span id="cb49-671"><a href="#cb49-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-674"><a href="#cb49-674" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-675"><a href="#cb49-675" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb49-676"><a href="#cb49-676" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb49-677"><a href="#cb49-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-678"><a href="#cb49-678" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the XGBoost parameters</span></span>
<span id="cb49-679"><a href="#cb49-679" aria-hidden="true" tabindex="-1"></a>  params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb49-680"><a href="#cb49-680" aria-hidden="true" tabindex="-1"></a>    <span class="at">booster =</span> <span class="st">"gbtree"</span>,</span>
<span id="cb49-681"><a href="#cb49-681" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"binary:logistic"</span>,</span>
<span id="cb49-682"><a href="#cb49-682" aria-hidden="true" tabindex="-1"></a>    <span class="at">eta =</span> <span class="fl">0.1</span>,  <span class="co"># learning rate</span></span>
<span id="cb49-683"><a href="#cb49-683" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="dv">6</span>,</span>
<span id="cb49-684"><a href="#cb49-684" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> <span class="dv">1</span>,</span>
<span id="cb49-685"><a href="#cb49-685" aria-hidden="true" tabindex="-1"></a>    <span class="at">subsample =</span> <span class="fl">0.8</span>,</span>
<span id="cb49-686"><a href="#cb49-686" aria-hidden="true" tabindex="-1"></a>    <span class="at">colsample_bytree =</span> <span class="fl">0.8</span>,</span>
<span id="cb49-687"><a href="#cb49-687" aria-hidden="true" tabindex="-1"></a>    <span class="at">eval_metric =</span> <span class="st">"error"</span></span>
<span id="cb49-688"><a href="#cb49-688" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-689"><a href="#cb49-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-690"><a href="#cb49-690" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb49-691"><a href="#cb49-691" aria-hidden="true" tabindex="-1"></a><span class="co"># Prevent the output from being printed in the rendered html document by using invisible()</span></span>
<span id="cb49-692"><a href="#cb49-692" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>({</span>
<span id="cb49-693"><a href="#cb49-693" aria-hidden="true" tabindex="-1"></a>  fit_xgb1 <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(</span>
<span id="cb49-694"><a href="#cb49-694" aria-hidden="true" tabindex="-1"></a>    <span class="at">params =</span> params, </span>
<span id="cb49-695"><a href="#cb49-695" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> train_xgb, </span>
<span id="cb49-696"><a href="#cb49-696" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">100</span>, </span>
<span id="cb49-697"><a href="#cb49-697" aria-hidden="true" tabindex="-1"></a>    <span class="at">watchlist =</span> <span class="fu">list</span>(<span class="at">train =</span> train_xgb, <span class="at">eval =</span> test_xgb), </span>
<span id="cb49-698"><a href="#cb49-698" aria-hidden="true" tabindex="-1"></a>    <span class="at">early_stopping_rounds =</span> <span class="dv">10</span>,</span>
<span id="cb49-699"><a href="#cb49-699" aria-hidden="true" tabindex="-1"></a>    <span class="at">print_every_n =</span> <span class="dv">10</span></span>
<span id="cb49-700"><a href="#cb49-700" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-701"><a href="#cb49-701" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb49-702"><a href="#cb49-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-703"><a href="#cb49-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-704"><a href="#cb49-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-705"><a href="#cb49-705" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-706"><a href="#cb49-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-707"><a href="#cb49-707" aria-hidden="true" tabindex="-1"></a>Make predictions using the XGBoost model and determine model performance.</span>
<span id="cb49-708"><a href="#cb49-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-711"><a href="#cb49-711" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-712"><a href="#cb49-712" aria-hidden="true" tabindex="-1"></a><span class="do">## Make predictions</span></span>
<span id="cb49-713"><a href="#cb49-713" aria-hidden="true" tabindex="-1"></a>probs_xgb1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_xgb1, <span class="at">newdata =</span> test_xgb)</span>
<span id="cb49-714"><a href="#cb49-714" aria-hidden="true" tabindex="-1"></a>pred_xgb1 <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(probs_xgb1 <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb49-715"><a href="#cb49-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-716"><a href="#cb49-716" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix to obtain model performance</span></span>
<span id="cb49-717"><a href="#cb49-717" aria-hidden="true" tabindex="-1"></a><span class="co"># Recap: sensitivity is the recall for the positive class</span></span>
<span id="cb49-718"><a href="#cb49-718" aria-hidden="true" tabindex="-1"></a><span class="co"># Recap: specificity is the recall for the negative class</span></span>
<span id="cb49-719"><a href="#cb49-719" aria-hidden="true" tabindex="-1"></a>confmatrix_xgb1 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(pred_xgb1), <span class="fu">factor</span>(y_test_label), <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb49-720"><a href="#cb49-720" aria-hidden="true" tabindex="-1"></a>sensitivity_xgb1 <span class="ot">&lt;-</span> confmatrix_xgb1<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>] </span>
<span id="cb49-721"><a href="#cb49-721" aria-hidden="true" tabindex="-1"></a>specificity_xgb1 <span class="ot">&lt;-</span> confmatrix_xgb1<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>] </span>
<span id="cb49-722"><a href="#cb49-722" aria-hidden="true" tabindex="-1"></a>precision_xgb1 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_xgb1<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb49-723"><a href="#cb49-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-724"><a href="#cb49-724" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the prediction function from the ROCR package to create a prediction object. This will be used later to create an ROC graph</span></span>
<span id="cb49-725"><a href="#cb49-725" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb49-726"><a href="#cb49-726" aria-hidden="true" tabindex="-1"></a><span class="co"># tpr = true positive rate, fpr = false positive rate</span></span>
<span id="cb49-727"><a href="#cb49-727" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the AUC (Area Under the Curve)</span></span>
<span id="cb49-728"><a href="#cb49-728" aria-hidden="true" tabindex="-1"></a>pred_object_xgb <span class="ot">&lt;-</span> <span class="fu">prediction</span>(probs_xgb1, y_test_label)</span>
<span id="cb49-729"><a href="#cb49-729" aria-hidden="true" tabindex="-1"></a>perf_xgb <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_xgb, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb49-730"><a href="#cb49-730" aria-hidden="true" tabindex="-1"></a>auc_xgb <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_xgb, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span>
<span id="cb49-731"><a href="#cb49-731" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-732"><a href="#cb49-732" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-733"><a href="#cb49-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-734"><a href="#cb49-734" aria-hidden="true" tabindex="-1"></a>As for the other models, I determine the importance of the different variables.</span>
<span id="cb49-735"><a href="#cb49-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-738"><a href="#cb49-738" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-739"><a href="#cb49-739" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb49-740"><a href="#cb49-740" aria-hidden="true" tabindex="-1"></a>importance_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.importance</span>(<span class="at">feature_names =</span> <span class="fu">colnames</span>(train_xgb), <span class="at">model =</span> fit_xgb1)</span>
<span id="cb49-741"><a href="#cb49-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-742"><a href="#cb49-742" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare a plot of the top 20 most important features</span></span>
<span id="cb49-743"><a href="#cb49-743" aria-hidden="true" tabindex="-1"></a><span class="co"># This function (with a ggplot-backend) performs 1-D clustering of the importance values.</span></span>
<span id="cb49-744"><a href="#cb49-744" aria-hidden="true" tabindex="-1"></a><span class="co"># Clusters with similar importance values get the same bar colours.</span></span>
<span id="cb49-745"><a href="#cb49-745" aria-hidden="true" tabindex="-1"></a>importance_plot_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.ggplot.importance</span>(<span class="at">importance_matrix =</span> importance_xgb,</span>
<span id="cb49-746"><a href="#cb49-746" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">top_n =</span> <span class="dv">20</span>, <span class="at">n_clusters =</span> <span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb49-747"><a href="#cb49-747" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb49-748"><a href="#cb49-748" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">theme</span>(</span>
<span id="cb49-749"><a href="#cb49-749" aria-hidden="true" tabindex="-1"></a>                      <span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb49-750"><a href="#cb49-750" aria-hidden="true" tabindex="-1"></a>                      <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb49-751"><a href="#cb49-751" aria-hidden="true" tabindex="-1"></a>                      <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>)</span>
<span id="cb49-752"><a href="#cb49-752" aria-hidden="true" tabindex="-1"></a>                      ) <span class="sc">+</span></span>
<span id="cb49-753"><a href="#cb49-753" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">ggtitle</span>(<span class="st">"XGBoost Variable Importance"</span>)</span>
<span id="cb49-754"><a href="#cb49-754" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-755"><a href="#cb49-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-756"><a href="#cb49-756" aria-hidden="true" tabindex="-1"></a><span class="fu">### Support Vector Classifier</span></span>
<span id="cb49-757"><a href="#cb49-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-758"><a href="#cb49-758" aria-hidden="true" tabindex="-1"></a>The support vector classifier (SVC) is a method that constructs a set of hyperplanes that separates the training data into two classes.</span>
<span id="cb49-759"><a href="#cb49-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-760"><a href="#cb49-760" aria-hidden="true" tabindex="-1"></a>I perform regularization by adjusting the cost tuning parameter (C), which allows changing the number and severity of the violations to the margin. A smaller C value increases the margin size by allowing more violations, while a larger C value reduces the margin and penalizes misclassifications more severely.</span>
<span id="cb49-761"><a href="#cb49-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-762"><a href="#cb49-762" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- How the C (cost) tuning parameter works: --&gt;</span></span>
<span id="cb49-763"><a href="#cb49-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-764"><a href="#cb49-764" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- C Tuning Parameter: The C parameter in SVC controls the degree of regularization. --&gt;</span></span>
<span id="cb49-765"><a href="#cb49-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-766"><a href="#cb49-766" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- A small C (more regularization) allows a larger margin with more violations (misclassified points), making the classifier more tolerant to errors, which can help generalize better. --&gt;</span></span>
<span id="cb49-767"><a href="#cb49-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-768"><a href="#cb49-768" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- A large C (less regularization) reduces the margin and penalizes violations more severely, making the classifier focus on correctly classifying all points, which may lead to overfitting. --&gt;</span></span>
<span id="cb49-769"><a href="#cb49-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-770"><a href="#cb49-770" aria-hidden="true" tabindex="-1"></a>The best value for the cost tuning parameter (C) is determined through cross validation.</span>
<span id="cb49-771"><a href="#cb49-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-774"><a href="#cb49-774" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-775"><a href="#cb49-775" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb49-776"><a href="#cb49-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-777"><a href="#cb49-777" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the SVC model at different values of the C tuning parameter</span></span>
<span id="cb49-778"><a href="#cb49-778" aria-hidden="true" tabindex="-1"></a><span class="co"># I use the built-in tune() function in the e1071 library</span></span>
<span id="cb49-779"><a href="#cb49-779" aria-hidden="true" tabindex="-1"></a><span class="co"># Train an SVM model with a linear kernel - corresponds to support vector classifier (SVC) </span></span>
<span id="cb49-780"><a href="#cb49-780" aria-hidden="true" tabindex="-1"></a><span class="co"># I explicitly remove education_num from the data frame, since with first run, just defining the formula, is not sufficient for excluding it from the model.</span></span>
<span id="cb49-781"><a href="#cb49-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-782"><a href="#cb49-782" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove education_num from the dataset before fitting the model</span></span>
<span id="cb49-783"><a href="#cb49-783" aria-hidden="true" tabindex="-1"></a>df_train_svc <span class="ot">&lt;-</span> df_train[, <span class="sc">!</span><span class="fu">colnames</span>(df_train) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"education_num"</span>)]</span>
<span id="cb49-784"><a href="#cb49-784" aria-hidden="true" tabindex="-1"></a>df_test_svc <span class="ot">&lt;-</span> df_test[, <span class="sc">!</span><span class="fu">colnames</span>(df_test) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"education_num"</span>)]</span>
<span id="cb49-785"><a href="#cb49-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-786"><a href="#cb49-786" aria-hidden="true" tabindex="-1"></a>svcf1 <span class="ot">&lt;-</span> income <span class="sc">~</span>. </span>
<span id="cb49-787"><a href="#cb49-787" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb49-788"><a href="#cb49-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-789"><a href="#cb49-789" aria-hidden="true" tabindex="-1"></a><span class="co"># Script for finding the optimal cost parameter through cross validation</span></span>
<span id="cb49-790"><a href="#cb49-790" aria-hidden="true" tabindex="-1"></a>tune_svc <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, svcf1, <span class="at">data =</span> df_train, <span class="at">kernel =</span> <span class="st">"linear"</span>,</span>
<span id="cb49-791"><a href="#cb49-791" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>)))</span>
<span id="cb49-792"><a href="#cb49-792" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-793"><a href="#cb49-793" aria-hidden="true" tabindex="-1"></a><span class="co"># This computation takes quite some time, so I am saving the results.</span></span>
<span id="cb49-794"><a href="#cb49-794" aria-hidden="true" tabindex="-1"></a><span class="co"># saveRDS(tune_svc, file = "posts/classification_adult_data/tune_svc.rds")</span></span>
<span id="cb49-795"><a href="#cb49-795" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb49-796"><a href="#cb49-796" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-797"><a href="#cb49-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-798"><a href="#cb49-798" aria-hidden="true" tabindex="-1"></a>Since the cross-validation for different values takes quite some time, I save the results for easy loading. I use the cost value that gives the smallest error for subsequent predictions.</span>
<span id="cb49-799"><a href="#cb49-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-802"><a href="#cb49-802" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-803"><a href="#cb49-803" aria-hidden="true" tabindex="-1"></a><span class="co">#~/Dropbox/Projects/Portfolio/posts/classification_adult_data</span></span>
<span id="cb49-804"><a href="#cb49-804" aria-hidden="true" tabindex="-1"></a><span class="co">#tune_svc &lt;- readRDS("/Users/Dropbox/Projects/Portfolio/posts/classification_adult_data/tune_svc.rds")</span></span>
<span id="cb49-805"><a href="#cb49-805" aria-hidden="true" tabindex="-1"></a>tune_svc <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"tune_svc_new.rds"</span>)</span>
<span id="cb49-806"><a href="#cb49-806" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_svc)</span>
<span id="cb49-807"><a href="#cb49-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-808"><a href="#cb49-808" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the best model</span></span>
<span id="cb49-809"><a href="#cb49-809" aria-hidden="true" tabindex="-1"></a>bestmod_svc <span class="ot">&lt;-</span> tune_svc<span class="sc">$</span>best.model</span>
<span id="cb49-810"><a href="#cb49-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-811"><a href="#cb49-811" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class and probabilities using the best model</span></span>
<span id="cb49-812"><a href="#cb49-812" aria-hidden="true" tabindex="-1"></a>pred_svc <span class="ot">&lt;-</span> <span class="fu">predict</span>(bestmod_svc, df_test, <span class="at">decision.values =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-813"><a href="#cb49-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-814"><a href="#cb49-814" aria-hidden="true" tabindex="-1"></a><span class="do">## Create confusion matrix to evaluate the model's performance</span></span>
<span id="cb49-815"><a href="#cb49-815" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract accuracy, precision, sensitivity and specificity</span></span>
<span id="cb49-816"><a href="#cb49-816" aria-hidden="true" tabindex="-1"></a>confmatrix_svc <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_svc, df_test<span class="sc">$</span>income, <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb49-817"><a href="#cb49-817" aria-hidden="true" tabindex="-1"></a>accuracy_svc <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(confmatrix_svc<span class="sc">$</span>overall[<span class="st">"Accuracy"</span>])</span>
<span id="cb49-818"><a href="#cb49-818" aria-hidden="true" tabindex="-1"></a>precision_svc <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">as.numeric</span>(confmatrix_svc<span class="sc">$</span>byClass[<span class="st">"Pos Pred Value"</span>]), <span class="dv">3</span>)</span>
<span id="cb49-819"><a href="#cb49-819" aria-hidden="true" tabindex="-1"></a>specificity_svc <span class="ot">&lt;-</span> confmatrix_svc<span class="sc">$</span>byClass[<span class="st">"Specificity"</span>]</span>
<span id="cb49-820"><a href="#cb49-820" aria-hidden="true" tabindex="-1"></a>sensitivity_svc <span class="ot">&lt;-</span> confmatrix_svc<span class="sc">$</span>byClass[<span class="st">"Sensitivity"</span>]</span>
<span id="cb49-821"><a href="#cb49-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-822"><a href="#cb49-822" aria-hidden="true" tabindex="-1"></a><span class="do">## ROC curve</span></span>
<span id="cb49-823"><a href="#cb49-823" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the decision values (distance from the decision boundary)</span></span>
<span id="cb49-824"><a href="#cb49-824" aria-hidden="true" tabindex="-1"></a>decision_values_svc <span class="ot">&lt;-</span> <span class="fu">attributes</span>(pred_svc)<span class="sc">$</span>decision.values</span>
<span id="cb49-825"><a href="#cb49-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-826"><a href="#cb49-826" aria-hidden="true" tabindex="-1"></a><span class="co"># Use ROCR package to plot the ROC curve</span></span>
<span id="cb49-827"><a href="#cb49-827" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a prediction object using decision values and true labels</span></span>
<span id="cb49-828"><a href="#cb49-828" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the negative of the fitted decision values so that negative values correspond to class 1 and the positive values to class 2 (ISLR p. 395).</span></span>
<span id="cb49-829"><a href="#cb49-829" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a performance object for the ROC curve</span></span>
<span id="cb49-830"><a href="#cb49-830" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the AUC (Area Under the Curve)</span></span>
<span id="cb49-831"><a href="#cb49-831" aria-hidden="true" tabindex="-1"></a>pred_object_svc <span class="ot">&lt;-</span> <span class="fu">prediction</span>(<span class="sc">-</span>decision_values_svc, y_test_label)</span>
<span id="cb49-832"><a href="#cb49-832" aria-hidden="true" tabindex="-1"></a>perf_svc <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_svc, <span class="st">"tpr"</span>, <span class="st">"fpr"</span>)</span>
<span id="cb49-833"><a href="#cb49-833" aria-hidden="true" tabindex="-1"></a>auc_svc <span class="ot">&lt;-</span> <span class="fu">performance</span>(pred_object_svc, <span class="at">measure =</span> <span class="st">"auc"</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span>
<span id="cb49-834"><a href="#cb49-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-835"><a href="#cb49-835" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-836"><a href="#cb49-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-837"><a href="#cb49-837" aria-hidden="true" tabindex="-1"></a>Determine the importance of the variables in this model.</span>
<span id="cb49-838"><a href="#cb49-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-841"><a href="#cb49-841" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-842"><a href="#cb49-842" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the importance of the different variables in the model</span></span>
<span id="cb49-843"><a href="#cb49-843" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients (weights) and support vectors, multiplying them gives the final coefficient (weight) for each feature in the decision boundary.</span></span>
<span id="cb49-844"><a href="#cb49-844" aria-hidden="true" tabindex="-1"></a>svc_coefficients <span class="ot">&lt;-</span> <span class="fu">t</span>(bestmod_svc<span class="sc">$</span>coefs) <span class="sc">%*%</span> bestmod_svc<span class="sc">$</span>SV</span>
<span id="cb49-845"><a href="#cb49-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-846"><a href="#cb49-846" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients and the names</span></span>
<span id="cb49-847"><a href="#cb49-847" aria-hidden="true" tabindex="-1"></a>svc_coeff_values <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(svc_coefficients)</span>
<span id="cb49-848"><a href="#cb49-848" aria-hidden="true" tabindex="-1"></a>variable_names <span class="ot">&lt;-</span> <span class="fu">dimnames</span>(svc_coefficients)[[<span class="dv">2</span>]]</span>
<span id="cb49-849"><a href="#cb49-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-850"><a href="#cb49-850" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the names and coefficients into a named vector</span></span>
<span id="cb49-851"><a href="#cb49-851" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember that in this case:</span></span>
<span id="cb49-852"><a href="#cb49-852" aria-hidden="true" tabindex="-1"></a><span class="co"># Positive coefficients (in the output from my SVM model) will push the decision toward the negative class.</span></span>
<span id="cb49-853"><a href="#cb49-853" aria-hidden="true" tabindex="-1"></a><span class="co"># Negative coefficients will push the decision toward the positive class.</span></span>
<span id="cb49-854"><a href="#cb49-854" aria-hidden="true" tabindex="-1"></a>svc_coefficients_named <span class="ot">&lt;-</span> <span class="fu">setNames</span>(<span class="sc">-</span>svc_coeff_values, variable_names)</span>
<span id="cb49-855"><a href="#cb49-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-856"><a href="#cb49-856" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the coefficients by their absolute values, keeping the names intact</span></span>
<span id="cb49-857"><a href="#cb49-857" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the top 20 largest estimates (based on absolute values)</span></span>
<span id="cb49-858"><a href="#cb49-858" aria-hidden="true" tabindex="-1"></a>svc_coefficients_ordered <span class="ot">&lt;-</span> svc_coefficients_named[<span class="fu">order</span>(<span class="fu">abs</span>(svc_coefficients_named), <span class="at">decreasing =</span> <span class="cn">TRUE</span>)]</span>
<span id="cb49-859"><a href="#cb49-859" aria-hidden="true" tabindex="-1"></a>importance_svc_top20 <span class="ot">&lt;-</span> svc_coefficients_ordered[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb49-860"><a href="#cb49-860" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-861"><a href="#cb49-861" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the named vector of top 20 into a dataframe for plotting</span></span>
<span id="cb49-862"><a href="#cb49-862" aria-hidden="true" tabindex="-1"></a>importance_svc_top20 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb49-863"><a href="#cb49-863" aria-hidden="true" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">names</span>(importance_svc_top20),</span>
<span id="cb49-864"><a href="#cb49-864" aria-hidden="true" tabindex="-1"></a>  <span class="at">Coefficient =</span> importance_svc_top20</span>
<span id="cb49-865"><a href="#cb49-865" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-866"><a href="#cb49-866" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-867"><a href="#cb49-867" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a bar plot with the actual values (not the absolute ones)</span></span>
<span id="cb49-868"><a href="#cb49-868" aria-hidden="true" tabindex="-1"></a>importance_plot_svc <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(importance_svc_top20, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="fu">abs</span>(Coefficient)), <span class="at">y =</span> Coefficient)) <span class="sc">+</span></span>
<span id="cb49-869"><a href="#cb49-869" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="fu">aes</span>(<span class="at">fill =</span> <span class="fu">ifelse</span>(Coefficient <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>))) <span class="sc">+</span></span>
<span id="cb49-870"><a href="#cb49-870" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb49-871"><a href="#cb49-871" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"SVC Variable Importance"</span>, </span>
<span id="cb49-872"><a href="#cb49-872" aria-hidden="true" tabindex="-1"></a>         <span class="at">x =</span> <span class="st">"Variables"</span>, </span>
<span id="cb49-873"><a href="#cb49-873" aria-hidden="true" tabindex="-1"></a>         <span class="at">y =</span> <span class="st">"Coefficient Value"</span>) <span class="sc">+</span></span>
<span id="cb49-874"><a href="#cb49-874" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-875"><a href="#cb49-875" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Negative"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>, <span class="st">"Positive"</span> <span class="ot">=</span> <span class="st">"steelblue"</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb49-876"><a href="#cb49-876" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),  </span>
<span id="cb49-877"><a href="#cb49-877" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb49-878"><a href="#cb49-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-879"><a href="#cb49-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-880"><a href="#cb49-880" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-881"><a href="#cb49-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-882"><a href="#cb49-882" aria-hidden="true" tabindex="-1"></a><span class="fu">## Results</span></span>
<span id="cb49-883"><a href="#cb49-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-884"><a href="#cb49-884" aria-hidden="true" tabindex="-1"></a>The main goal of this post is to identify which statistical method performs best in predicting annual income in the adult census data. Nevertheless, I still think it is interesting to look at the variable importance across the different methods.</span>
<span id="cb49-885"><a href="#cb49-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-886"><a href="#cb49-886" aria-hidden="true" tabindex="-1"></a>The figures below show the 20 most important variables in the different methods used.</span>
<span id="cb49-887"><a href="#cb49-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-890"><a href="#cb49-890" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-891"><a href="#cb49-891" aria-hidden="true" tabindex="-1"></a><span class="co">#| layout-ncol: 2</span></span>
<span id="cb49-892"><a href="#cb49-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-893"><a href="#cb49-893" aria-hidden="true" tabindex="-1"></a>importance_plot_glm</span>
<span id="cb49-894"><a href="#cb49-894" aria-hidden="true" tabindex="-1"></a>importance_plot_ridge</span>
<span id="cb49-895"><a href="#cb49-895" aria-hidden="true" tabindex="-1"></a>importance_plot_xgb</span>
<span id="cb49-896"><a href="#cb49-896" aria-hidden="true" tabindex="-1"></a>importance_plot_svc</span>
<span id="cb49-897"><a href="#cb49-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-898"><a href="#cb49-898" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-899"><a href="#cb49-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-900"><a href="#cb49-900" aria-hidden="true" tabindex="-1"></a>The figure below shows the ROC curves and AUC for the different methods.</span>
<span id="cb49-901"><a href="#cb49-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-904"><a href="#cb49-904" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-905"><a href="#cb49-905" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_svc, <span class="at">col =</span> <span class="st">"green"</span>, <span class="at">main =</span> <span class="st">"ROC Curves"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>)</span>
<span id="cb49-906"><a href="#cb49-906" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_xgb, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-907"><a href="#cb49-907" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_glmf2, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-908"><a href="#cb49-908" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(perf_ridge, <span class="at">col =</span> <span class="st">"purple"</span>, <span class="at">lwd =</span> <span class="fl">0.8</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-909"><a href="#cb49-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-910"><a href="#cb49-910" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend to the plot with AUC values</span></span>
<span id="cb49-911"><a href="#cb49-911" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomright"</span>,</span>
<span id="cb49-912"><a href="#cb49-912" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="fu">paste</span>(<span class="st">"SVM AUC:"</span>, <span class="fu">round</span>(auc_svc, <span class="dv">3</span>)),</span>
<span id="cb49-913"><a href="#cb49-913" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">paste</span>(<span class="st">"XGBoost AUC:"</span>, <span class="fu">round</span>(auc_xgb, <span class="dv">3</span>)),</span>
<span id="cb49-914"><a href="#cb49-914" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">paste</span>(<span class="st">"Logistic Regression AUC:"</span>, <span class="fu">round</span>(auc_glmf2, <span class="dv">3</span>)),</span>
<span id="cb49-915"><a href="#cb49-915" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">paste</span>(<span class="st">"Ridge Regression AUC:"</span>, <span class="fu">round</span>(auc_ridge, <span class="dv">3</span>))),</span>
<span id="cb49-916"><a href="#cb49-916" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"green"</span>, <span class="st">"red"</span>, <span class="st">"blue"</span>, <span class="st">"purple"</span>),</span>
<span id="cb49-917"><a href="#cb49-917" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb49-918"><a href="#cb49-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-919"><a href="#cb49-919" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-920"><a href="#cb49-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-921"><a href="#cb49-921" aria-hidden="true" tabindex="-1"></a>The following table shows the performance of the different methods used as measured by the metrics sensitivity, specificity and precision.</span>
<span id="cb49-922"><a href="#cb49-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-925"><a href="#cb49-925" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-926"><a href="#cb49-926" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect all the results in a data frame</span></span>
<span id="cb49-927"><a href="#cb49-927" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb49-928"><a href="#cb49-928" aria-hidden="true" tabindex="-1"></a>  <span class="at">Method =</span> <span class="fu">c</span>(<span class="st">"Logistic Regression"</span>, <span class="st">"Ridge Regression"</span>, <span class="st">"XGBoost"</span>, <span class="st">"Support Vector Classifier"</span>),</span>
<span id="cb49-929"><a href="#cb49-929" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sensitivity =</span> <span class="fu">c</span>(sensitivity_glmf2, sensitivity_ridge, sensitivity_xgb1, sensitivity_svc),</span>
<span id="cb49-930"><a href="#cb49-930" aria-hidden="true" tabindex="-1"></a>  <span class="at">Specificity =</span> <span class="fu">c</span>(specificity_glmf2, specificity_ridge, specificity_xgb1, specificity_svc),</span>
<span id="cb49-931"><a href="#cb49-931" aria-hidden="true" tabindex="-1"></a>  <span class="at">Precision =</span> <span class="fu">c</span>(precision_glmf2, precision_ridge, precision_xgb1, precision_svc)</span>
<span id="cb49-932"><a href="#cb49-932" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-933"><a href="#cb49-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-934"><a href="#cb49-934" aria-hidden="true" tabindex="-1"></a><span class="co"># Order the results by Precision in descending order</span></span>
<span id="cb49-935"><a href="#cb49-935" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> results[<span class="fu">order</span>(<span class="sc">-</span>results<span class="sc">$</span>Precision), ]</span>
<span id="cb49-936"><a href="#cb49-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-937"><a href="#cb49-937" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the values for a clean display</span></span>
<span id="cb49-938"><a href="#cb49-938" aria-hidden="true" tabindex="-1"></a>results[, <span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="fu">round</span>(results[, <span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>], <span class="dv">3</span>)</span>
<span id="cb49-939"><a href="#cb49-939" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-940"><a href="#cb49-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-941"><a href="#cb49-941" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion</span></span>
<span id="cb49-942"><a href="#cb49-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-943"><a href="#cb49-943" aria-hidden="true" tabindex="-1"></a>Whereas logistic regression can give important information for making inferences about the importance of the different variables and their effects, XGBoost and the SVC are not designed for making direct inferences. XGBoost and the SVC are primarily predictive models that focus on maximizing predictive accuracy.</span>
<span id="cb49-944"><a href="#cb49-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-945"><a href="#cb49-945" aria-hidden="true" tabindex="-1"></a><span class="fu">## Skills</span></span>
<span id="cb49-946"><a href="#cb49-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-947"><a href="#cb49-947" aria-hidden="true" tabindex="-1"></a>Statistical learning, machine learning, R-programming, Tableau and data visualization.</span>
<span id="cb49-948"><a href="#cb49-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-949"><a href="#cb49-949" aria-hidden="true" tabindex="-1"></a>References:\</span>
<span id="cb49-950"><a href="#cb49-950" aria-hidden="true" tabindex="-1"></a>Becker, Barry and Kohavi, Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.  </span>
<span id="cb49-951"><a href="#cb49-951" aria-hidden="true" tabindex="-1"></a>James, G., Witten, D., Hastie, T. og Tibshirani, R. 2021. An Introduction to Statistical Learning (ISLR): with Applications in R. Available at: https://link.springer.com/content/pdf/10. 1007/978-1-0716-1418-1.pdf.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>